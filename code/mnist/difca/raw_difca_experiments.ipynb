{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OHJWesKs-tqd"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import itertools\n",
        "import pickle\n",
        "import copy\n",
        "import random\n",
        "import math\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from util import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAghP_o0-tqe"
      },
      "source": [
        "Reads Config file and prepares the arguments you can choose in the config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BbUZJ2E--tqe"
      },
      "outputs": [],
      "source": [
        "LR_DECAY = False\n",
        "def get_config():\n",
        "\n",
        "    # read config json and update the sysarg\n",
        "    with open(\"config.json\", \"r\") as read_file:\n",
        "        config = json.load(read_file)\n",
        "\n",
        "    if config[\"config_override\"] == \"\":\n",
        "        del config['config_override']\n",
        "    else:\n",
        "        print(config['config_override'])\n",
        "        config_override = json.loads(config['config_override'])\n",
        "        del config['config_override']\n",
        "        config.update(config_override)\n",
        "\n",
        "    return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-J1YEoM-tqe"
      },
      "source": [
        "Class SimpleLinear with simple MLP for MNIST Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "id5Wyt-V-tqf"
      },
      "outputs": [],
      "source": [
        "class SimpleLinear(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, h1=2048):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(28*28, h1)\n",
        "        self.fc2 = torch.nn.Linear(h1, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # x = F.sigmoid(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    # def weight(self):\n",
        "    #     return self.linear1.weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qFBH01M-tqf"
      },
      "source": [
        "Class TrainMNISTCluster with all the methods needed to run the experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IkGiGQ2G-tqf"
      },
      "outputs": [],
      "source": [
        "class TrainMNISTCluster(object):\n",
        "    def __init__(self, config, device):\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        assert self.config['m'] % self.config['p'] == 0\n",
        "\n",
        "    def setup(self):\n",
        "\n",
        "        os.makedirs(self.config['project_dir'], exist_ok = True)\n",
        "\n",
        "        self.result_fname = os.path.join(self.config['project_dir'], 'results.pickle')\n",
        "        self.checkpoint_fname = os.path.join(self.config['project_dir'], 'checkpoint.pt')\n",
        "\n",
        "        self.setup_datasets()\n",
        "        self.setup_models()\n",
        "\n",
        "        self.epoch = None\n",
        "        self.lr = None\n",
        "\n",
        "\n",
        "    def setup_datasets(self):\n",
        "\n",
        "        np.random.seed(self.config['data_seed'])\n",
        "\n",
        "        # generate indices for each dataset\n",
        "        # also write cluster info\n",
        "\n",
        "        MNIST_TRAINSET_DATA_SIZE = 60000\n",
        "        MNIST_TESTSET_DATA_SIZE = 10000\n",
        "\n",
        "        np.random.seed(self.config['data_seed'])\n",
        "\n",
        "        cfg = self.config\n",
        "\n",
        "        self.dataset = {}\n",
        "\n",
        "        if cfg['uneven'] == True:\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset_random_n(MNIST_TRAINSET_DATA_SIZE, cfg['p'], cfg['m'], cfg['n'])\n",
        "            (X, y) = self._load_MNIST(train=True)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['train'] = dataset\n",
        "\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset_random_n(MNIST_TESTSET_DATA_SIZE, cfg['p'], cfg['m_test'], cfg['n'], random=True)\n",
        "            (X, y) = self._load_MNIST(train=False)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['test'] = dataset\n",
        "\n",
        "        else:\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset(MNIST_TRAINSET_DATA_SIZE, cfg['p'], cfg['m'], cfg['n'])\n",
        "            (X, y) = self._load_MNIST(train=True)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['train'] = dataset\n",
        "\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset(MNIST_TESTSET_DATA_SIZE, cfg['p'], cfg['m_test'], cfg['n'], random=True)\n",
        "            (X, y) = self._load_MNIST(train=False)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['test'] = dataset\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def _setup_dataset_random_n(self, num_data, p, m, n, random = True):\n",
        "\n",
        "        print(\"m:\",m)\n",
        "        print(\"p:\",p)\n",
        "        print(\"num_data:\",num_data)\n",
        "\n",
        "        dataset = {}\n",
        "\n",
        "        cfg = self.config\n",
        "\n",
        "        data_indices = []\n",
        "        cluster_assign = []\n",
        "\n",
        "        m_per_cluster = m // p\n",
        "\n",
        "        for p_i in range(p):\n",
        "\n",
        "            ll = list(np.random.permutation(num_data))\n",
        "\n",
        "            ll2 = chunkify_uneven(ll, m_per_cluster) # splits ll into m lists\n",
        "            data_indices += ll2\n",
        "\n",
        "            cluster_assign += [p_i for _ in range(m_per_cluster)]\n",
        "\n",
        "        data_indices = np.array(data_indices, dtype=object)\n",
        "        cluster_assign = np.array(cluster_assign)\n",
        "        assert data_indices.shape[0] == cluster_assign.shape[0]\n",
        "        assert data_indices.shape[0] == m\n",
        "\n",
        "\n",
        "        return data_indices, cluster_assign\n",
        "\n",
        "\n",
        "    def _load_MNIST(self, train=True):\n",
        "        transforms = torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               # torchvision.transforms.Normalize(\n",
        "                               #   (0.1307,), (0.3081,))\n",
        "                             ])\n",
        "        if train:\n",
        "            mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms)\n",
        "        else:\n",
        "            mnist_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms)\n",
        "\n",
        "        dl = DataLoader(mnist_dataset)\n",
        "\n",
        "        X = dl.dataset.data # (60000,28, 28)\n",
        "        y = dl.dataset.targets #(60000)\n",
        "\n",
        "        # normalize to have 0 ~ 1 range in each pixel\n",
        "\n",
        "        X = X / 255.0\n",
        "        X = X.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "    # Need p models for each client\n",
        "\n",
        "    def setup_models(self):\n",
        "        np.random.seed(self.config['train_seed'])\n",
        "        torch.manual_seed(self.config['train_seed'])\n",
        "\n",
        "        p = self.config['p']\n",
        "\n",
        "        self.models = [ SimpleLinear(h1 = self.config['h1']).to(self.device) for p_i in range(p)] # p models with p different params of dimension(1,d)\n",
        "\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        num_epochs = self.config['num_epochs']\n",
        "        lr = self.config['lr']\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # epoch -1\n",
        "        self.epoch = -1\n",
        "\n",
        "        result = {}\n",
        "        result['epoch'] = -1\n",
        "\n",
        "        t0 = time.time()\n",
        "        res = self.test(train=True)\n",
        "        t1 = time.time()\n",
        "        res['infer_time'] = t1-t0\n",
        "        result['train'] = res\n",
        "\n",
        "        self.print_epoch_stats(res)\n",
        "\n",
        "        t0 = time.time()\n",
        "        res = self.test(train=False)\n",
        "        t1 = time.time()\n",
        "        res['infer_time'] = t1-t0\n",
        "        result['test'] = res\n",
        "        self.print_epoch_stats(res)\n",
        "        results.append(result)\n",
        "\n",
        "        # this will be used in next epoch\n",
        "        cluster_assign = result['train']['cluster_assign']\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.epoch = epoch\n",
        "\n",
        "            result = {}\n",
        "            result['epoch'] = epoch\n",
        "\n",
        "            lr = self.lr_schedule(epoch)\n",
        "            result['lr'] = lr\n",
        "\n",
        "            t0 = time.time()\n",
        "            result['train'] = self.train(cluster_assign, lr = lr)\n",
        "            t1 = time.time()\n",
        "            train_time = t1-t0\n",
        "\n",
        "            t0 = time.time()\n",
        "            res = self.test(train=True)\n",
        "            t1 = time.time()\n",
        "            res['infer_time'] = t1-t0\n",
        "            res['train_time'] = train_time\n",
        "            res['lr'] = lr\n",
        "            result['train'] = res\n",
        "\n",
        "            self.print_epoch_stats(res)\n",
        "\n",
        "            t0 = time.time()\n",
        "            res = self.test(train=False)\n",
        "            t1 = time.time()\n",
        "            res['infer_time'] = t1-t0\n",
        "            result['test'] = res\n",
        "            self.print_epoch_stats(res)\n",
        "\n",
        "            results.append(result)\n",
        "\n",
        "            # this will be used in next epoch's gradient update\n",
        "            cluster_assign = result['train']['cluster_assign']\n",
        "\n",
        "            if epoch % 10 == 0 or epoch == num_epochs - 1 :\n",
        "                with open(self.result_fname, 'wb') as outfile:\n",
        "                    pickle.dump(results, outfile)\n",
        "                    print(f'result written at {self.result_fname}')\n",
        "                self.save_checkpoint()\n",
        "                print(f'checkpoint written at {self.checkpoint_fname}')\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.plot([r['train']['loss'] for r in results], label='train')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('loss')\n",
        "        plt.title('Training Loss per Epoch')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(self.config['project_dir'], 'train_loss.png'))\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.plot([r['test']['acc'] for r in results], label='train')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('test accuracy')\n",
        "        plt.title('Test Accuracy per Epoch')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(self.config['project_dir'], 'test_acc.png'))\n",
        "\n",
        "\n",
        "    def lr_schedule(self, epoch):\n",
        "        if self.lr is None:\n",
        "            self.lr = self.config['lr']\n",
        "\n",
        "        if epoch % 50 == 0 and epoch != 0 and LR_DECAY:\n",
        "            self.lr = self.lr * 0.1\n",
        "\n",
        "        return self.lr\n",
        "\n",
        "\n",
        "    def print_epoch_stats(self, res):\n",
        "        if res['is_train']:\n",
        "            data_str = 'tr'\n",
        "        else:\n",
        "            data_str = 'tst'\n",
        "\n",
        "        if 'train_time' in res:\n",
        "            time_str = f\"{res['train_time']:.3f}sec(train) {res['infer_time']:.3f}sec(infer)\"\n",
        "        else:\n",
        "            time_str = f\"{res['infer_time']:.3f}sec\"\n",
        "\n",
        "        if 'lr' in res:\n",
        "            lr_str = f\" lr {res['lr']:4f}\"\n",
        "        else:\n",
        "            lr_str = \"\"\n",
        "\n",
        "        str0 = f\"Epoch {self.epoch} {data_str}: l {res['loss']:.3f} a {res['acc']:.3f} clct{res['cl_ct']}{lr_str} {time_str}\"\n",
        "\n",
        "        print(str0)\n",
        "\n",
        "    def train(self, cluster_assign, lr):\n",
        "        VERBOSE = 0\n",
        "\n",
        "        cfg = self.config\n",
        "        m = cfg['m']\n",
        "        p = cfg['p']\n",
        "        tau = cfg['tau']\n",
        "\n",
        "        # run local update\n",
        "        t0 = time.time()\n",
        "\n",
        "\n",
        "        updated_models = []\n",
        "        for m_i in range(m):\n",
        "            if VERBOSE and m_i % 100 == 0: print(f'm {m_i}/{m} processing \\r', end ='')\n",
        "\n",
        "            (X, y) = self.load_data(m_i)\n",
        "\n",
        "            p_i = cluster_assign[m_i]\n",
        "            model = copy.deepcopy(self.models[p_i])\n",
        "\n",
        "            # LOCAL UPDATE PER MACHINE tau times\n",
        "            for step_i in range(tau):\n",
        "\n",
        "                y_logit = model(X)\n",
        "                loss = self.criterion(y_logit, y)\n",
        "\n",
        "                model.zero_grad()\n",
        "                loss.backward()\n",
        "                self.local_param_update(model, lr)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            updated_models.append(model)\n",
        "\n",
        "        t02 = time.time()\n",
        "        # print(f'running single ..took {t02-t01:.3f}sec')\n",
        "\n",
        "\n",
        "        t1 = time.time()\n",
        "        if VERBOSE: print(f'local update {t1-t0:.3f}sec')\n",
        "\n",
        "        # apply gradient update\n",
        "        t0 = time.time()\n",
        "\n",
        "        # CLUSTER MACHINES INTO p_i's\n",
        "        local_models = [[] for p_i in range(p)]\n",
        "        for m_i in range(m):\n",
        "            p_i = cluster_assign[m_i]\n",
        "            local_models[p_i].append(updated_models[m_i])\n",
        "\n",
        "        # NEEDS TO BE DECENTRALIZED\n",
        "        for p_i, models in enumerate(local_models):\n",
        "            if len(models) > 0:\n",
        "                self.dec_param_update(models, self.models[p_i])\n",
        "        t1 = time.time()\n",
        "\n",
        "        if VERBOSE: print(f'global update {t1-t0:.3f}sec')\n",
        "\n",
        "    def check_local_model_loss(self, local_models):\n",
        "        # for debugging\n",
        "        m = self.config['m']\n",
        "\n",
        "        losses = []\n",
        "        for m_i in range(m):\n",
        "            (X, y) = self.load_data(m_i)\n",
        "            y_logit = local_models[m_i](X)\n",
        "            loss = self.criterion(y_logit, y)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        return np.array(losses)\n",
        "\n",
        "\n",
        "    def get_inference_stats(self, train = True):\n",
        "        cfg = self.config\n",
        "        if train:\n",
        "            m = cfg['m']\n",
        "            dataset = self.dataset['train']\n",
        "        else:\n",
        "            m = cfg['m_test']\n",
        "            dataset = self.dataset['test']\n",
        "\n",
        "        p = cfg['p']\n",
        "\n",
        "\n",
        "        num_data = 0\n",
        "        losses = {}\n",
        "        corrects = {}\n",
        "        for m_i in range(m):\n",
        "            (X, y) = self.load_data(m_i, train=train) # load batch data rotated\n",
        "\n",
        "            for p_i in range(p):\n",
        "                y_logit = self.models[p_i](X)\n",
        "                loss = self.criterion(y_logit, y) # loss of\n",
        "                n_correct = self.n_correct(y_logit, y)\n",
        "\n",
        "                # if torch.isnan(loss):\n",
        "                #     print(\"nan loss: \", dataset['data_indices'][m_i])\n",
        "\n",
        "                losses[(m_i,p_i)] = loss.item()\n",
        "                corrects[(m_i,p_i)] = n_correct\n",
        "\n",
        "            num_data += X.shape[0]\n",
        "\n",
        "        # calculate loss and cluster the machines\n",
        "        cluster_assign = []\n",
        "        for m_i in range(m):\n",
        "            machine_losses = [ losses[(m_i,p_i)] for p_i in range(p) ]\n",
        "            min_p_i = np.argmin(machine_losses)\n",
        "            cluster_assign.append(min_p_i)\n",
        "\n",
        "        # calculate optimal model's loss, acc over all models\n",
        "        min_corrects = []\n",
        "        min_losses = []\n",
        "        for m_i, p_i in enumerate(cluster_assign):\n",
        "\n",
        "            min_loss = losses[(m_i,p_i)]\n",
        "            min_losses.append(min_loss)\n",
        "\n",
        "            min_correct = corrects[(m_i,p_i)]\n",
        "            min_corrects.append(min_correct)\n",
        "\n",
        "        # print(\"losses: \", min_losses)\n",
        "        loss = np.mean(min_losses)\n",
        "        acc = np.sum(min_corrects) / num_data\n",
        "\n",
        "\n",
        "        # check cluster assignment acc\n",
        "        cl_acc = np.mean(np.array(cluster_assign) == np.array(dataset['cluster_assign']))\n",
        "        cl_ct = [np.sum(np.array(cluster_assign) == p_i ) for p_i in range(p)]\n",
        "\n",
        "        res = {} # results\n",
        "        # res['losses'] = losses\n",
        "        # res['corrects'] = corrects\n",
        "        res['cluster_assign'] = cluster_assign\n",
        "        res['num_data'] = num_data\n",
        "        res['loss'] = loss\n",
        "        res['acc'] = acc\n",
        "        res['cl_acc'] = cl_acc\n",
        "        res['cl_ct'] = cl_ct\n",
        "        res['is_train'] = train\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "        return res\n",
        "\n",
        "    def n_correct(self, y_logit, y):\n",
        "        _, predicted = torch.max(y_logit.data, 1)\n",
        "        correct = (predicted == y).sum().item()\n",
        "\n",
        "        return correct\n",
        "\n",
        "    # TODO Does every Cluster get 4 clients with the same data, but rotated differently?\n",
        "\n",
        "    def load_data(self, m_i, train=True):\n",
        "        # this part is very fast since its just rearranging models\n",
        "        cfg = self.config\n",
        "\n",
        "        if train:\n",
        "            dataset = self.dataset['train']\n",
        "        else:\n",
        "            dataset = self.dataset['test']\n",
        "\n",
        "        indices = dataset['data_indices'][m_i]\n",
        "        p_i = dataset['cluster_assign'][m_i]\n",
        "\n",
        "        X_batch = dataset['X'][indices]\n",
        "        y_batch = dataset['y'][indices]\n",
        "\n",
        "        # k : how many times rotate 90 degree\n",
        "        # k =1 : 90 , k=2 180, k=3 270\n",
        "\n",
        "        if cfg['p'] == 4:\n",
        "            k = p_i\n",
        "        elif cfg['p'] == 2:\n",
        "            k = (p_i % 2) * 2\n",
        "        elif cfg['p'] == 1:\n",
        "            k = 0\n",
        "        else:\n",
        "            raise NotImplementedError(\"only p=1,2,4 supported\")\n",
        "\n",
        "        X_batch2 = torch.rot90(X_batch, k=int(k), dims = (1,2))\n",
        "        X_batch3 = X_batch2.reshape(-1, 28 * 28)\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "        return X_batch3, y_batch\n",
        "\n",
        "\n",
        "    def local_param_update(self, model, lr):\n",
        "\n",
        "        # gradient update manually\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                param.data -= lr * param.grad\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # import ipdb; ipdb.set_trace() # we need to check the output of name, check if duplicate exists\n",
        "\n",
        "\n",
        "    def dec_param_update(self, local_models, global_model):\n",
        "\n",
        "        num_clients = len(local_models)\n",
        "\n",
        "        if num_clients == 0:\n",
        "            return\n",
        "\n",
        "        if num_clients == 1:\n",
        "            bc_client = dict(local_models[0].named_parameters())\n",
        "            for name, param in global_model.named_parameters():\n",
        "                param.data = bc_client[name].data.clone()\n",
        "            return\n",
        "\n",
        "        max_e = 100\n",
        "        if num_clients <= max_e:\n",
        "            e = num_clients - 1\n",
        "        else:\n",
        "            e = min(max_e, int(np.log(num_clients) * 10))\n",
        "\n",
        "        if e >= num_clients:\n",
        "            e = num_clients - 1\n",
        "\n",
        "        client_indices = list(range(num_clients))\n",
        "\n",
        "        for m_i, local_model in enumerate(local_models):\n",
        "            selected_clients = random.sample([i for i in client_indices if i != m_i], e)\n",
        "\n",
        "            for m_j in selected_clients:\n",
        "\n",
        "                m_j_params = dict(local_models[m_j].named_parameters())\n",
        "\n",
        "                for name, param in local_model.named_parameters():\n",
        "                    m_i_param = param.data.clone()\n",
        "                    m_j_param = m_j_params[name].data.clone()\n",
        "                    param.data = (m_i_param + m_j_param) / 2\n",
        "\n",
        "        bc_client = random.choice(client_indices)\n",
        "        bc_client_params = dict(local_models[bc_client].named_parameters())\n",
        "        for name, param in global_model.named_parameters():\n",
        "            param.data = bc_client_params[name].data.clone()\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def test(self, train=False):\n",
        "        return self.get_inference_stats(train=train)\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        models_to_save = [model.state_dict() for model in self.models]\n",
        "        torch.save({'models':models_to_save}, self.checkpoint_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ADsUSUi-tqf"
      },
      "source": [
        "Running the Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T_XDv25r-tqf",
        "outputId": "1dda7e5a-27bd-46d0-c125-b6987383650d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config: {'m': 1200, 'm_test': 200, 'p': 4, 'n': 100, 'uneven': True, 'h1': 200, 'num_epochs': 200, 'batch_size': 100, 'tau': 10, 'lr': 0.1, 'data_seed': 10, 'train_seed': 10, 'project_dir': 'content'}\n",
            "Using device: cuda\n",
            "m: 1200\n",
            "p: 4\n",
            "num_data: 60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "m: 200\n",
            "p: 4\n",
            "num_data: 10000\n",
            "len:  10000\n",
            "len:  10000\n",
            "len:  10000\n",
            "len:  10000\n",
            "Epoch -1 tr: l 2.294 a 0.113 clct[346, 317, 154, 383] 2.764sec\n",
            "Epoch -1 tst: l 2.292 a 0.114 clct[53, 69, 22, 56] 0.328sec\n",
            "Epoch 0 tr: l 2.165 a 0.358 clct[309, 269, 302, 320] lr 0.100000 27.247sec(train) 1.967sec(infer)\n",
            "Epoch 0 tst: l 2.164 a 0.363 clct[48, 48, 49, 55] 0.340sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 1 tr: l 1.881 a 0.591 clct[300, 300, 300, 300] lr 0.100000 27.496sec(train) 1.934sec(infer)\n",
            "Epoch 1 tst: l 1.877 a 0.591 clct[49, 50, 50, 51] 0.341sec\n",
            "Epoch 2 tr: l 1.543 a 0.700 clct[300, 300, 300, 300] lr 0.100000 28.884sec(train) 1.971sec(infer)\n",
            "Epoch 2 tst: l 1.535 a 0.704 clct[50, 50, 50, 50] 0.327sec\n",
            "Epoch 3 tr: l 1.239 a 0.748 clct[300, 300, 300, 300] lr 0.100000 27.258sec(train) 1.956sec(infer)\n",
            "Epoch 3 tst: l 1.230 a 0.755 clct[50, 50, 50, 50] 0.352sec\n",
            "Epoch 4 tr: l 1.029 a 0.777 clct[300, 300, 300, 300] lr 0.100000 27.297sec(train) 2.292sec(infer)\n",
            "Epoch 4 tst: l 1.018 a 0.784 clct[50, 50, 50, 50] 0.468sec\n",
            "Epoch 5 tr: l 0.871 a 0.813 clct[300, 300, 300, 300] lr 0.100000 27.634sec(train) 1.982sec(infer)\n",
            "Epoch 5 tst: l 0.859 a 0.818 clct[50, 50, 50, 50] 0.333sec\n",
            "Epoch 6 tr: l 0.803 a 0.799 clct[300, 300, 300, 300] lr 0.100000 26.947sec(train) 1.963sec(infer)\n",
            "Epoch 6 tst: l 0.793 a 0.806 clct[50, 50, 50, 50] 0.334sec\n",
            "Epoch 7 tr: l 0.697 a 0.837 clct[300, 300, 300, 300] lr 0.100000 28.351sec(train) 2.439sec(infer)\n",
            "Epoch 7 tst: l 0.686 a 0.845 clct[50, 50, 50, 50] 0.334sec\n",
            "Epoch 8 tr: l 0.636 a 0.847 clct[300, 300, 300, 300] lr 0.100000 27.082sec(train) 1.978sec(infer)\n",
            "Epoch 8 tst: l 0.626 a 0.854 clct[50, 50, 50, 50] 0.332sec\n",
            "Epoch 9 tr: l 0.600 a 0.845 clct[300, 300, 300, 300] lr 0.100000 27.299sec(train) 1.943sec(infer)\n",
            "Epoch 9 tst: l 0.593 a 0.851 clct[50, 50, 50, 50] 0.332sec\n",
            "Epoch 10 tr: l 0.561 a 0.855 clct[300, 300, 300, 300] lr 0.100000 27.983sec(train) 1.999sec(infer)\n",
            "Epoch 10 tst: l 0.552 a 0.863 clct[50, 50, 50, 50] 0.335sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 11 tr: l 0.530 a 0.862 clct[300, 300, 300, 300] lr 0.100000 27.281sec(train) 1.965sec(infer)\n",
            "Epoch 11 tst: l 0.523 a 0.870 clct[50, 50, 50, 50] 0.326sec\n",
            "Epoch 12 tr: l 0.510 a 0.865 clct[300, 300, 300, 300] lr 0.100000 26.997sec(train) 2.230sec(infer)\n",
            "Epoch 12 tst: l 0.503 a 0.872 clct[50, 50, 50, 50] 0.459sec\n",
            "Epoch 13 tr: l 0.496 a 0.865 clct[300, 300, 300, 300] lr 0.100000 27.534sec(train) 1.987sec(infer)\n",
            "Epoch 13 tst: l 0.488 a 0.873 clct[50, 50, 50, 50] 0.331sec\n",
            "Epoch 14 tr: l 0.474 a 0.872 clct[300, 300, 300, 300] lr 0.100000 27.147sec(train) 1.990sec(infer)\n",
            "Epoch 14 tst: l 0.466 a 0.880 clct[50, 50, 50, 50] 0.353sec\n",
            "Epoch 15 tr: l 0.459 a 0.874 clct[300, 300, 300, 300] lr 0.100000 27.129sec(train) 2.581sec(infer)\n",
            "Epoch 15 tst: l 0.453 a 0.882 clct[50, 50, 50, 50] 0.349sec\n",
            "Epoch 16 tr: l 0.451 a 0.876 clct[300, 300, 300, 300] lr 0.100000 27.144sec(train) 1.956sec(infer)\n",
            "Epoch 16 tst: l 0.443 a 0.882 clct[50, 50, 50, 50] 0.331sec\n",
            "Epoch 17 tr: l 0.436 a 0.879 clct[300, 300, 300, 300] lr 0.100000 26.845sec(train) 1.969sec(infer)\n",
            "Epoch 17 tst: l 0.430 a 0.886 clct[50, 50, 50, 50] 0.327sec\n",
            "Epoch 18 tr: l 0.428 a 0.880 clct[300, 300, 300, 300] lr 0.100000 28.301sec(train) 2.028sec(infer)\n",
            "Epoch 18 tst: l 0.420 a 0.886 clct[50, 50, 50, 50] 0.338sec\n",
            "Epoch 19 tr: l 0.418 a 0.883 clct[300, 300, 300, 300] lr 0.100000 26.863sec(train) 1.951sec(infer)\n",
            "Epoch 19 tst: l 0.412 a 0.889 clct[50, 50, 50, 50] 0.340sec\n",
            "Epoch 20 tr: l 0.410 a 0.884 clct[300, 300, 300, 300] lr 0.100000 27.288sec(train) 2.251sec(infer)\n",
            "Epoch 20 tst: l 0.403 a 0.890 clct[50, 50, 50, 50] 0.492sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 21 tr: l 0.405 a 0.885 clct[300, 300, 300, 300] lr 0.100000 28.012sec(train) 1.976sec(infer)\n",
            "Epoch 21 tst: l 0.397 a 0.892 clct[50, 50, 50, 50] 0.348sec\n",
            "Epoch 22 tr: l 0.401 a 0.886 clct[300, 300, 300, 300] lr 0.100000 27.425sec(train) 1.959sec(infer)\n",
            "Epoch 22 tst: l 0.396 a 0.892 clct[50, 50, 50, 50] 0.365sec\n",
            "Epoch 23 tr: l 0.409 a 0.878 clct[300, 300, 300, 300] lr 0.100000 27.817sec(train) 2.450sec(infer)\n",
            "Epoch 23 tst: l 0.408 a 0.884 clct[50, 50, 50, 50] 0.369sec\n",
            "Epoch 24 tr: l 0.391 a 0.887 clct[300, 300, 300, 300] lr 0.100000 27.229sec(train) 1.976sec(infer)\n",
            "Epoch 24 tst: l 0.386 a 0.893 clct[50, 50, 50, 50] 0.351sec\n",
            "Epoch 25 tr: l 0.399 a 0.881 clct[300, 300, 300, 300] lr 0.100000 27.436sec(train) 2.007sec(infer)\n",
            "Epoch 25 tst: l 0.395 a 0.887 clct[50, 50, 50, 50] 0.489sec\n",
            "Epoch 26 tr: l 0.380 a 0.889 clct[300, 300, 300, 300] lr 0.100000 28.160sec(train) 1.969sec(infer)\n",
            "Epoch 26 tst: l 0.375 a 0.896 clct[50, 50, 50, 50] 0.333sec\n",
            "Epoch 27 tr: l 0.376 a 0.890 clct[300, 300, 300, 300] lr 0.100000 27.443sec(train) 1.980sec(infer)\n",
            "Epoch 27 tst: l 0.373 a 0.895 clct[50, 50, 50, 50] 0.350sec\n",
            "Epoch 28 tr: l 0.366 a 0.893 clct[300, 300, 300, 300] lr 0.100000 27.737sec(train) 2.714sec(infer)\n",
            "Epoch 28 tst: l 0.363 a 0.899 clct[50, 50, 50, 50] 0.340sec\n",
            "Epoch 29 tr: l 0.367 a 0.893 clct[300, 300, 300, 300] lr 0.100000 27.565sec(train) 2.024sec(infer)\n",
            "Epoch 29 tst: l 0.363 a 0.898 clct[50, 50, 50, 50] 0.330sec\n",
            "Epoch 30 tr: l 0.361 a 0.894 clct[300, 300, 300, 300] lr 0.100000 27.802sec(train) 1.977sec(infer)\n",
            "Epoch 30 tst: l 0.358 a 0.900 clct[50, 50, 50, 50] 0.370sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 31 tr: l 0.355 a 0.897 clct[300, 300, 300, 300] lr 0.100000 28.690sec(train) 2.001sec(infer)\n",
            "Epoch 31 tst: l 0.352 a 0.903 clct[50, 50, 50, 50] 0.326sec\n",
            "Epoch 32 tr: l 0.351 a 0.898 clct[300, 300, 300, 300] lr 0.100000 27.671sec(train) 1.941sec(infer)\n",
            "Epoch 32 tst: l 0.349 a 0.903 clct[50, 50, 50, 50] 0.337sec\n",
            "Epoch 33 tr: l 0.350 a 0.898 clct[300, 300, 300, 300] lr 0.100000 27.332sec(train) 2.693sec(infer)\n",
            "Epoch 33 tst: l 0.348 a 0.904 clct[50, 50, 50, 50] 0.437sec\n",
            "Epoch 34 tr: l 0.351 a 0.897 clct[300, 300, 300, 300] lr 0.100000 28.911sec(train) 2.214sec(infer)\n",
            "Epoch 34 tst: l 0.349 a 0.903 clct[50, 50, 50, 50] 0.379sec\n",
            "Epoch 35 tr: l 0.348 a 0.897 clct[300, 300, 300, 300] lr 0.100000 29.350sec(train) 2.449sec(infer)\n",
            "Epoch 35 tst: l 0.345 a 0.903 clct[50, 50, 50, 50] 0.505sec\n",
            "Epoch 36 tr: l 0.342 a 0.900 clct[300, 300, 300, 300] lr 0.100000 27.906sec(train) 1.978sec(infer)\n",
            "Epoch 36 tst: l 0.340 a 0.905 clct[50, 50, 50, 50] 0.350sec\n",
            "Epoch 37 tr: l 0.341 a 0.899 clct[300, 300, 300, 300] lr 0.100000 27.396sec(train) 1.970sec(infer)\n",
            "Epoch 37 tst: l 0.340 a 0.905 clct[50, 50, 50, 50] 0.328sec\n",
            "Epoch 38 tr: l 0.339 a 0.900 clct[300, 300, 300, 300] lr 0.100000 28.701sec(train) 2.154sec(infer)\n",
            "Epoch 38 tst: l 0.340 a 0.905 clct[50, 50, 50, 50] 0.351sec\n",
            "Epoch 39 tr: l 0.336 a 0.901 clct[300, 300, 300, 300] lr 0.100000 27.748sec(train) 1.976sec(infer)\n",
            "Epoch 39 tst: l 0.336 a 0.907 clct[50, 50, 50, 50] 0.345sec\n",
            "Epoch 40 tr: l 0.332 a 0.902 clct[300, 300, 300, 300] lr 0.100000 27.701sec(train) 2.377sec(infer)\n",
            "Epoch 40 tst: l 0.332 a 0.906 clct[50, 50, 50, 50] 0.596sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 41 tr: l 0.332 a 0.902 clct[300, 300, 300, 300] lr 0.100000 28.350sec(train) 2.043sec(infer)\n",
            "Epoch 41 tst: l 0.332 a 0.907 clct[50, 50, 50, 50] 0.375sec\n",
            "Epoch 42 tr: l 0.331 a 0.902 clct[300, 300, 300, 300] lr 0.100000 27.698sec(train) 1.991sec(infer)\n",
            "Epoch 42 tst: l 0.330 a 0.907 clct[50, 50, 50, 50] 0.356sec\n",
            "Epoch 43 tr: l 0.327 a 0.904 clct[300, 300, 300, 300] lr 0.100000 28.715sec(train) 1.995sec(infer)\n",
            "Epoch 43 tst: l 0.326 a 0.908 clct[50, 50, 50, 50] 0.339sec\n",
            "Epoch 44 tr: l 0.326 a 0.902 clct[300, 300, 300, 300] lr 0.100000 27.483sec(train) 1.970sec(infer)\n",
            "Epoch 44 tst: l 0.326 a 0.908 clct[50, 50, 50, 50] 0.358sec\n",
            "Epoch 45 tr: l 0.322 a 0.906 clct[300, 300, 300, 300] lr 0.100000 27.631sec(train) 2.660sec(infer)\n",
            "Epoch 45 tst: l 0.319 a 0.910 clct[50, 50, 50, 50] 0.428sec\n",
            "Epoch 46 tr: l 0.327 a 0.902 clct[300, 300, 300, 300] lr 0.100000 27.613sec(train) 2.011sec(infer)\n",
            "Epoch 46 tst: l 0.327 a 0.907 clct[50, 50, 50, 50] 0.356sec\n",
            "Epoch 47 tr: l 0.327 a 0.902 clct[300, 300, 300, 300] lr 0.100000 27.628sec(train) 2.036sec(infer)\n",
            "Epoch 47 tst: l 0.326 a 0.908 clct[50, 50, 50, 50] 0.359sec\n",
            "Epoch 48 tr: l 0.322 a 0.904 clct[300, 300, 300, 300] lr 0.100000 28.555sec(train) 2.039sec(infer)\n",
            "Epoch 48 tst: l 0.321 a 0.909 clct[50, 50, 50, 50] 0.361sec\n",
            "Epoch 49 tr: l 0.314 a 0.907 clct[300, 300, 300, 300] lr 0.100000 27.587sec(train) 1.986sec(infer)\n",
            "Epoch 49 tst: l 0.314 a 0.911 clct[50, 50, 50, 50] 0.342sec\n",
            "Epoch 50 tr: l 0.315 a 0.907 clct[300, 300, 300, 300] lr 0.100000 27.420sec(train) 2.459sec(infer)\n",
            "Epoch 50 tst: l 0.315 a 0.911 clct[50, 50, 50, 50] 0.513sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 51 tr: l 0.320 a 0.904 clct[300, 300, 300, 300] lr 0.100000 27.123sec(train) 1.962sec(infer)\n",
            "Epoch 51 tst: l 0.320 a 0.908 clct[50, 50, 50, 50] 0.336sec\n",
            "Epoch 52 tr: l 0.313 a 0.906 clct[300, 300, 300, 300] lr 0.100000 27.339sec(train) 1.949sec(infer)\n",
            "Epoch 52 tst: l 0.315 a 0.911 clct[50, 50, 50, 50] 0.338sec\n",
            "Epoch 53 tr: l 0.312 a 0.907 clct[300, 300, 300, 300] lr 0.100000 27.659sec(train) 2.240sec(infer)\n",
            "Epoch 53 tst: l 0.314 a 0.911 clct[50, 50, 50, 50] 0.369sec\n",
            "Epoch 54 tr: l 0.309 a 0.907 clct[300, 300, 300, 300] lr 0.100000 26.944sec(train) 1.954sec(infer)\n",
            "Epoch 54 tst: l 0.311 a 0.911 clct[50, 50, 50, 50] 0.325sec\n",
            "Epoch 55 tr: l 0.306 a 0.908 clct[300, 300, 300, 300] lr 0.100000 27.449sec(train) 2.020sec(infer)\n",
            "Epoch 55 tst: l 0.307 a 0.912 clct[50, 50, 50, 50] 0.478sec\n",
            "Epoch 56 tr: l 0.308 a 0.909 clct[300, 300, 300, 300] lr 0.100000 27.794sec(train) 1.968sec(infer)\n",
            "Epoch 56 tst: l 0.310 a 0.912 clct[50, 50, 50, 50] 0.326sec\n",
            "Epoch 57 tr: l 0.308 a 0.908 clct[300, 300, 300, 300] lr 0.100000 27.114sec(train) 2.018sec(infer)\n",
            "Epoch 57 tst: l 0.309 a 0.913 clct[50, 50, 50, 50] 0.327sec\n",
            "Epoch 58 tr: l 0.308 a 0.908 clct[300, 300, 300, 300] lr 0.100000 26.739sec(train) 2.437sec(infer)\n",
            "Epoch 58 tst: l 0.312 a 0.912 clct[50, 50, 50, 50] 0.532sec\n",
            "Epoch 59 tr: l 0.307 a 0.909 clct[300, 300, 300, 300] lr 0.100000 27.574sec(train) 1.981sec(infer)\n",
            "Epoch 59 tst: l 0.311 a 0.913 clct[50, 50, 50, 50] 0.328sec\n",
            "Epoch 60 tr: l 0.303 a 0.910 clct[300, 300, 300, 300] lr 0.100000 26.775sec(train) 1.955sec(infer)\n",
            "Epoch 60 tst: l 0.305 a 0.914 clct[50, 50, 50, 50] 0.325sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 61 tr: l 0.313 a 0.905 clct[300, 300, 300, 300] lr 0.100000 27.440sec(train) 2.312sec(infer)\n",
            "Epoch 61 tst: l 0.315 a 0.910 clct[50, 50, 50, 50] 0.361sec\n",
            "Epoch 62 tr: l 0.300 a 0.910 clct[300, 300, 300, 300] lr 0.100000 26.767sec(train) 1.921sec(infer)\n",
            "Epoch 62 tst: l 0.304 a 0.914 clct[50, 50, 50, 50] 0.346sec\n",
            "Epoch 63 tr: l 0.297 a 0.911 clct[300, 300, 300, 300] lr 0.100000 26.882sec(train) 1.933sec(infer)\n",
            "Epoch 63 tst: l 0.300 a 0.916 clct[50, 50, 50, 50] 0.328sec\n",
            "Epoch 64 tr: l 0.303 a 0.910 clct[300, 300, 300, 300] lr 0.100000 27.758sec(train) 1.943sec(infer)\n",
            "Epoch 64 tst: l 0.307 a 0.913 clct[50, 50, 50, 50] 0.337sec\n",
            "Epoch 65 tr: l 0.297 a 0.911 clct[300, 300, 300, 300] lr 0.100000 26.891sec(train) 1.933sec(infer)\n",
            "Epoch 65 tst: l 0.303 a 0.916 clct[50, 50, 50, 50] 0.342sec\n",
            "Epoch 66 tr: l 0.294 a 0.913 clct[300, 300, 300, 300] lr 0.100000 27.090sec(train) 2.262sec(infer)\n",
            "Epoch 66 tst: l 0.296 a 0.918 clct[50, 50, 50, 50] 0.484sec\n",
            "Epoch 67 tr: l 0.290 a 0.914 clct[300, 300, 300, 300] lr 0.100000 27.346sec(train) 1.951sec(infer)\n",
            "Epoch 67 tst: l 0.294 a 0.918 clct[50, 50, 50, 50] 0.334sec\n",
            "Epoch 68 tr: l 0.293 a 0.912 clct[300, 300, 300, 300] lr 0.100000 26.946sec(train) 1.969sec(infer)\n",
            "Epoch 68 tst: l 0.295 a 0.917 clct[50, 50, 50, 50] 0.335sec\n",
            "Epoch 69 tr: l 0.293 a 0.913 clct[300, 300, 300, 300] lr 0.100000 26.810sec(train) 2.709sec(infer)\n",
            "Epoch 69 tst: l 0.297 a 0.918 clct[50, 50, 50, 50] 0.378sec\n",
            "Epoch 70 tr: l 0.289 a 0.914 clct[300, 300, 300, 300] lr 0.100000 27.082sec(train) 2.007sec(infer)\n",
            "Epoch 70 tst: l 0.293 a 0.917 clct[50, 50, 50, 50] 0.329sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 71 tr: l 0.291 a 0.913 clct[300, 300, 300, 300] lr 0.100000 26.999sec(train) 1.993sec(infer)\n",
            "Epoch 71 tst: l 0.298 a 0.916 clct[50, 50, 50, 50] 0.326sec\n",
            "Epoch 72 tr: l 0.284 a 0.915 clct[300, 300, 300, 300] lr 0.100000 27.823sec(train) 2.426sec(infer)\n",
            "Epoch 72 tst: l 0.290 a 0.918 clct[50, 50, 50, 50] 0.385sec\n",
            "Epoch 73 tr: l 0.282 a 0.916 clct[300, 300, 300, 300] lr 0.100000 27.327sec(train) 2.010sec(infer)\n",
            "Epoch 73 tst: l 0.288 a 0.919 clct[50, 50, 50, 50] 0.326sec\n",
            "Epoch 74 tr: l 0.283 a 0.915 clct[300, 300, 300, 300] lr 0.100000 26.938sec(train) 1.980sec(infer)\n",
            "Epoch 74 tst: l 0.288 a 0.919 clct[50, 50, 50, 50] 0.450sec\n",
            "Epoch 75 tr: l 0.282 a 0.916 clct[300, 300, 300, 300] lr 0.100000 28.068sec(train) 1.962sec(infer)\n",
            "Epoch 75 tst: l 0.286 a 0.919 clct[50, 50, 50, 50] 0.333sec\n",
            "Epoch 76 tr: l 0.281 a 0.916 clct[300, 300, 300, 300] lr 0.100000 26.943sec(train) 1.939sec(infer)\n",
            "Epoch 76 tst: l 0.286 a 0.919 clct[50, 50, 50, 50] 0.350sec\n",
            "Epoch 77 tr: l 0.278 a 0.917 clct[300, 300, 300, 300] lr 0.100000 27.068sec(train) 2.126sec(infer)\n",
            "Epoch 77 tst: l 0.284 a 0.920 clct[50, 50, 50, 50] 0.445sec\n",
            "Epoch 78 tr: l 0.280 a 0.917 clct[300, 300, 300, 300] lr 0.100000 27.417sec(train) 1.971sec(infer)\n",
            "Epoch 78 tst: l 0.286 a 0.920 clct[50, 50, 50, 50] 0.321sec\n",
            "Epoch 79 tr: l 0.277 a 0.917 clct[300, 300, 300, 300] lr 0.100000 27.155sec(train) 1.971sec(infer)\n",
            "Epoch 79 tst: l 0.281 a 0.921 clct[50, 50, 50, 50] 0.332sec\n",
            "Epoch 80 tr: l 0.284 a 0.914 clct[300, 300, 300, 300] lr 0.100000 27.220sec(train) 2.359sec(infer)\n",
            "Epoch 80 tst: l 0.287 a 0.918 clct[50, 50, 50, 50] 0.518sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 81 tr: l 0.278 a 0.917 clct[300, 300, 300, 300] lr 0.100000 27.032sec(train) 1.945sec(infer)\n",
            "Epoch 81 tst: l 0.282 a 0.919 clct[50, 50, 50, 50] 0.327sec\n",
            "Epoch 82 tr: l 0.273 a 0.918 clct[300, 300, 300, 300] lr 0.100000 26.959sec(train) 1.922sec(infer)\n",
            "Epoch 82 tst: l 0.277 a 0.921 clct[50, 50, 50, 50] 0.333sec\n",
            "Epoch 83 tr: l 0.277 a 0.916 clct[300, 300, 300, 300] lr 0.100000 26.910sec(train) 2.763sec(infer)\n",
            "Epoch 83 tst: l 0.282 a 0.919 clct[50, 50, 50, 50] 0.331sec\n",
            "Epoch 84 tr: l 0.275 a 0.917 clct[300, 300, 300, 300] lr 0.100000 27.106sec(train) 1.929sec(infer)\n",
            "Epoch 84 tst: l 0.279 a 0.919 clct[50, 50, 50, 50] 0.333sec\n",
            "Epoch 85 tr: l 0.271 a 0.919 clct[300, 300, 300, 300] lr 0.100000 26.947sec(train) 1.921sec(infer)\n",
            "Epoch 85 tst: l 0.275 a 0.921 clct[50, 50, 50, 50] 0.336sec\n",
            "Epoch 86 tr: l 0.271 a 0.919 clct[300, 300, 300, 300] lr 0.100000 27.352sec(train) 2.583sec(infer)\n",
            "Epoch 86 tst: l 0.277 a 0.921 clct[50, 50, 50, 50] 0.350sec\n",
            "Epoch 87 tr: l 0.269 a 0.920 clct[300, 300, 300, 300] lr 0.100000 26.929sec(train) 1.952sec(infer)\n",
            "Epoch 87 tst: l 0.276 a 0.922 clct[50, 50, 50, 50] 0.314sec\n",
            "Epoch 88 tr: l 0.271 a 0.919 clct[300, 300, 300, 300] lr 0.100000 27.006sec(train) 1.963sec(infer)\n",
            "Epoch 88 tst: l 0.277 a 0.921 clct[50, 50, 50, 50] 0.321sec\n",
            "Epoch 89 tr: l 0.272 a 0.919 clct[300, 300, 300, 300] lr 0.100000 27.096sec(train) 2.461sec(infer)\n",
            "Epoch 89 tst: l 0.275 a 0.921 clct[50, 50, 50, 50] 0.333sec\n",
            "Epoch 90 tr: l 0.274 a 0.917 clct[300, 300, 300, 300] lr 0.100000 26.879sec(train) 1.942sec(infer)\n",
            "Epoch 90 tst: l 0.278 a 0.921 clct[50, 50, 50, 50] 0.343sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 91 tr: l 0.266 a 0.920 clct[300, 300, 300, 300] lr 0.100000 27.102sec(train) 1.964sec(infer)\n",
            "Epoch 91 tst: l 0.273 a 0.923 clct[50, 50, 50, 50] 0.330sec\n",
            "Epoch 92 tr: l 0.266 a 0.920 clct[300, 300, 300, 300] lr 0.100000 27.470sec(train) 2.124sec(infer)\n",
            "Epoch 92 tst: l 0.273 a 0.923 clct[50, 50, 50, 50] 0.329sec\n",
            "Epoch 93 tr: l 0.267 a 0.919 clct[300, 300, 300, 300] lr 0.100000 26.994sec(train) 1.958sec(infer)\n",
            "Epoch 93 tst: l 0.274 a 0.922 clct[50, 50, 50, 50] 0.332sec\n",
            "Epoch 94 tr: l 0.262 a 0.921 clct[300, 300, 300, 300] lr 0.100000 26.827sec(train) 1.989sec(infer)\n",
            "Epoch 94 tst: l 0.271 a 0.924 clct[50, 50, 50, 50] 0.449sec\n",
            "Epoch 95 tr: l 0.260 a 0.922 clct[300, 300, 300, 300] lr 0.100000 27.871sec(train) 1.986sec(infer)\n",
            "Epoch 95 tst: l 0.269 a 0.925 clct[50, 50, 50, 50] 0.338sec\n",
            "Epoch 96 tr: l 0.260 a 0.922 clct[300, 300, 300, 300] lr 0.100000 26.884sec(train) 1.946sec(infer)\n",
            "Epoch 96 tst: l 0.269 a 0.924 clct[50, 50, 50, 50] 0.347sec\n",
            "Epoch 97 tr: l 0.264 a 0.921 clct[300, 300, 300, 300] lr 0.100000 27.040sec(train) 2.290sec(infer)\n",
            "Epoch 97 tst: l 0.272 a 0.923 clct[50, 50, 50, 50] 0.502sec\n",
            "Epoch 98 tr: l 0.268 a 0.919 clct[300, 300, 300, 300] lr 0.100000 27.774sec(train) 1.982sec(infer)\n",
            "Epoch 98 tst: l 0.273 a 0.921 clct[50, 50, 50, 50] 0.347sec\n",
            "Epoch 99 tr: l 0.259 a 0.922 clct[300, 300, 300, 300] lr 0.100000 27.107sec(train) 1.967sec(infer)\n",
            "Epoch 99 tst: l 0.264 a 0.924 clct[50, 50, 50, 50] 0.335sec\n",
            "Epoch 100 tr: l 0.258 a 0.923 clct[300, 300, 300, 300] lr 0.100000 26.982sec(train) 2.402sec(infer)\n",
            "Epoch 100 tst: l 0.264 a 0.925 clct[50, 50, 50, 50] 0.484sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 101 tr: l 0.255 a 0.924 clct[300, 300, 300, 300] lr 0.100000 27.187sec(train) 1.981sec(infer)\n",
            "Epoch 101 tst: l 0.262 a 0.927 clct[50, 50, 50, 50] 0.341sec\n",
            "Epoch 102 tr: l 0.254 a 0.924 clct[300, 300, 300, 300] lr 0.100000 26.962sec(train) 1.964sec(infer)\n",
            "Epoch 102 tst: l 0.261 a 0.926 clct[50, 50, 50, 50] 0.320sec\n",
            "Epoch 103 tr: l 0.271 a 0.917 clct[300, 300, 300, 300] lr 0.100000 27.073sec(train) 2.528sec(infer)\n",
            "Epoch 103 tst: l 0.285 a 0.918 clct[50, 50, 50, 50] 0.354sec\n",
            "Epoch 104 tr: l 0.261 a 0.921 clct[300, 300, 300, 300] lr 0.100000 27.126sec(train) 1.946sec(infer)\n",
            "Epoch 104 tst: l 0.271 a 0.922 clct[50, 50, 50, 50] 0.342sec\n",
            "Epoch 105 tr: l 0.256 a 0.923 clct[300, 300, 300, 300] lr 0.100000 26.914sec(train) 1.948sec(infer)\n",
            "Epoch 105 tst: l 0.266 a 0.925 clct[50, 50, 50, 50] 0.319sec\n",
            "Epoch 106 tr: l 0.253 a 0.924 clct[300, 300, 300, 300] lr 0.100000 28.141sec(train) 2.416sec(infer)\n",
            "Epoch 106 tst: l 0.262 a 0.926 clct[50, 50, 50, 50] 0.327sec\n",
            "Epoch 107 tr: l 0.252 a 0.924 clct[300, 300, 300, 300] lr 0.100000 27.256sec(train) 1.949sec(infer)\n",
            "Epoch 107 tst: l 0.261 a 0.926 clct[50, 50, 50, 50] 0.345sec\n",
            "Epoch 108 tr: l 0.252 a 0.924 clct[300, 300, 300, 300] lr 0.100000 27.009sec(train) 1.955sec(infer)\n",
            "Epoch 108 tst: l 0.260 a 0.926 clct[50, 50, 50, 50] 0.350sec\n",
            "Epoch 109 tr: l 0.247 a 0.926 clct[300, 300, 300, 300] lr 0.100000 28.057sec(train) 1.938sec(infer)\n",
            "Epoch 109 tst: l 0.257 a 0.928 clct[50, 50, 50, 50] 0.352sec\n",
            "Epoch 110 tr: l 0.248 a 0.925 clct[300, 300, 300, 300] lr 0.100000 26.806sec(train) 1.935sec(infer)\n",
            "Epoch 110 tst: l 0.259 a 0.927 clct[50, 50, 50, 50] 0.343sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 111 tr: l 0.245 a 0.927 clct[300, 300, 300, 300] lr 0.100000 27.209sec(train) 2.158sec(infer)\n",
            "Epoch 111 tst: l 0.256 a 0.929 clct[50, 50, 50, 50] 0.426sec\n",
            "Epoch 112 tr: l 0.247 a 0.926 clct[300, 300, 300, 300] lr 0.100000 27.663sec(train) 1.941sec(infer)\n",
            "Epoch 112 tst: l 0.260 a 0.928 clct[50, 50, 50, 50] 0.336sec\n",
            "Epoch 113 tr: l 0.247 a 0.925 clct[300, 300, 300, 300] lr 0.100000 27.375sec(train) 1.939sec(infer)\n",
            "Epoch 113 tst: l 0.259 a 0.928 clct[50, 50, 50, 50] 0.327sec\n",
            "Epoch 114 tr: l 0.244 a 0.927 clct[300, 300, 300, 300] lr 0.100000 26.923sec(train) 2.446sec(infer)\n",
            "Epoch 114 tst: l 0.255 a 0.928 clct[50, 50, 50, 50] 0.500sec\n",
            "Epoch 115 tr: l 0.242 a 0.928 clct[300, 300, 300, 300] lr 0.100000 27.084sec(train) 1.886sec(infer)\n",
            "Epoch 115 tst: l 0.254 a 0.929 clct[50, 50, 50, 50] 0.331sec\n",
            "Epoch 116 tr: l 0.246 a 0.926 clct[300, 300, 300, 300] lr 0.100000 27.156sec(train) 1.938sec(infer)\n",
            "Epoch 116 tst: l 0.256 a 0.928 clct[50, 50, 50, 50] 0.327sec\n",
            "Epoch 117 tr: l 0.242 a 0.927 clct[300, 300, 300, 300] lr 0.100000 26.829sec(train) 2.646sec(infer)\n",
            "Epoch 117 tst: l 0.252 a 0.929 clct[50, 50, 50, 50] 0.336sec\n",
            "Epoch 118 tr: l 0.239 a 0.928 clct[300, 300, 300, 300] lr 0.100000 27.096sec(train) 1.957sec(infer)\n",
            "Epoch 118 tst: l 0.250 a 0.930 clct[50, 50, 50, 50] 0.330sec\n",
            "Epoch 119 tr: l 0.239 a 0.929 clct[300, 300, 300, 300] lr 0.100000 26.805sec(train) 1.934sec(infer)\n",
            "Epoch 119 tst: l 0.251 a 0.930 clct[50, 50, 50, 50] 0.324sec\n",
            "Epoch 120 tr: l 0.238 a 0.928 clct[300, 300, 300, 300] lr 0.100000 27.180sec(train) 2.756sec(infer)\n",
            "Epoch 120 tst: l 0.248 a 0.930 clct[50, 50, 50, 50] 0.357sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 121 tr: l 0.238 a 0.929 clct[300, 300, 300, 300] lr 0.100000 26.691sec(train) 1.948sec(infer)\n",
            "Epoch 121 tst: l 0.248 a 0.931 clct[50, 50, 50, 50] 0.329sec\n",
            "Epoch 122 tr: l 0.238 a 0.929 clct[300, 300, 300, 300] lr 0.100000 27.059sec(train) 1.981sec(infer)\n",
            "Epoch 122 tst: l 0.248 a 0.930 clct[50, 50, 50, 50] 0.321sec\n",
            "Epoch 123 tr: l 0.236 a 0.929 clct[300, 300, 300, 300] lr 0.100000 27.278sec(train) 2.427sec(infer)\n",
            "Epoch 123 tst: l 0.247 a 0.931 clct[50, 50, 50, 50] 0.324sec\n",
            "Epoch 124 tr: l 0.235 a 0.930 clct[300, 300, 300, 300] lr 0.100000 26.618sec(train) 2.010sec(infer)\n",
            "Epoch 124 tst: l 0.246 a 0.931 clct[50, 50, 50, 50] 0.336sec\n",
            "Epoch 125 tr: l 0.237 a 0.929 clct[300, 300, 300, 300] lr 0.100000 26.951sec(train) 1.941sec(infer)\n",
            "Epoch 125 tst: l 0.249 a 0.930 clct[50, 50, 50, 50] 0.359sec\n",
            "Epoch 126 tr: l 0.235 a 0.929 clct[300, 300, 300, 300] lr 0.100000 27.180sec(train) 2.408sec(infer)\n",
            "Epoch 126 tst: l 0.246 a 0.931 clct[50, 50, 50, 50] 0.355sec\n",
            "Epoch 127 tr: l 0.235 a 0.929 clct[300, 300, 300, 300] lr 0.100000 27.051sec(train) 1.924sec(infer)\n",
            "Epoch 127 tst: l 0.245 a 0.931 clct[50, 50, 50, 50] 0.320sec\n",
            "Epoch 128 tr: l 0.233 a 0.930 clct[300, 300, 300, 300] lr 0.100000 26.695sec(train) 1.933sec(infer)\n",
            "Epoch 128 tst: l 0.244 a 0.931 clct[50, 50, 50, 50] 0.334sec\n",
            "Epoch 129 tr: l 0.235 a 0.929 clct[300, 300, 300, 300] lr 0.100000 27.165sec(train) 2.317sec(infer)\n",
            "Epoch 129 tst: l 0.246 a 0.930 clct[50, 50, 50, 50] 0.334sec\n",
            "Epoch 130 tr: l 0.233 a 0.930 clct[300, 300, 300, 300] lr 0.100000 27.137sec(train) 1.955sec(infer)\n",
            "Epoch 130 tst: l 0.244 a 0.931 clct[50, 50, 50, 50] 0.334sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 131 tr: l 0.230 a 0.931 clct[300, 300, 300, 300] lr 0.100000 26.815sec(train) 1.925sec(infer)\n",
            "Epoch 131 tst: l 0.242 a 0.932 clct[50, 50, 50, 50] 0.328sec\n",
            "Epoch 132 tr: l 0.231 a 0.930 clct[300, 300, 300, 300] lr 0.100000 27.973sec(train) 1.962sec(infer)\n",
            "Epoch 132 tst: l 0.243 a 0.931 clct[50, 50, 50, 50] 0.346sec\n",
            "Epoch 133 tr: l 0.230 a 0.931 clct[300, 300, 300, 300] lr 0.100000 26.673sec(train) 1.923sec(infer)\n",
            "Epoch 133 tst: l 0.240 a 0.932 clct[50, 50, 50, 50] 0.337sec\n",
            "Epoch 134 tr: l 0.227 a 0.932 clct[300, 300, 300, 300] lr 0.100000 27.037sec(train) 2.048sec(infer)\n",
            "Epoch 134 tst: l 0.239 a 0.932 clct[50, 50, 50, 50] 0.433sec\n",
            "Epoch 135 tr: l 0.230 a 0.931 clct[300, 300, 300, 300] lr 0.100000 27.688sec(train) 1.952sec(infer)\n",
            "Epoch 135 tst: l 0.240 a 0.932 clct[50, 50, 50, 50] 0.328sec\n",
            "Epoch 136 tr: l 0.232 a 0.929 clct[300, 300, 300, 300] lr 0.100000 26.981sec(train) 1.955sec(infer)\n",
            "Epoch 136 tst: l 0.242 a 0.930 clct[50, 50, 50, 50] 0.341sec\n",
            "Epoch 137 tr: l 0.226 a 0.932 clct[300, 300, 300, 300] lr 0.100000 26.877sec(train) 2.164sec(infer)\n",
            "Epoch 137 tst: l 0.238 a 0.933 clct[50, 50, 50, 50] 0.464sec\n",
            "Epoch 138 tr: l 0.227 a 0.932 clct[300, 300, 300, 300] lr 0.100000 27.686sec(train) 1.956sec(infer)\n",
            "Epoch 138 tst: l 0.241 a 0.933 clct[50, 50, 50, 50] 0.346sec\n",
            "Epoch 139 tr: l 0.230 a 0.930 clct[300, 300, 300, 300] lr 0.100000 26.970sec(train) 1.969sec(infer)\n",
            "Epoch 139 tst: l 0.246 a 0.931 clct[50, 50, 50, 50] 0.353sec\n",
            "Epoch 140 tr: l 0.226 a 0.932 clct[300, 300, 300, 300] lr 0.100000 27.693sec(train) 2.615sec(infer)\n",
            "Epoch 140 tst: l 0.240 a 0.932 clct[50, 50, 50, 50] 0.529sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 141 tr: l 0.223 a 0.932 clct[300, 300, 300, 300] lr 0.100000 27.035sec(train) 1.946sec(infer)\n",
            "Epoch 141 tst: l 0.235 a 0.933 clct[50, 50, 50, 50] 0.331sec\n",
            "Epoch 142 tr: l 0.225 a 0.931 clct[300, 300, 300, 300] lr 0.100000 26.771sec(train) 1.959sec(infer)\n",
            "Epoch 142 tst: l 0.238 a 0.932 clct[50, 50, 50, 50] 0.338sec\n",
            "Epoch 143 tr: l 0.224 a 0.932 clct[300, 300, 300, 300] lr 0.100000 27.266sec(train) 2.680sec(infer)\n",
            "Epoch 143 tst: l 0.234 a 0.933 clct[50, 50, 50, 50] 0.332sec\n",
            "Epoch 144 tr: l 0.221 a 0.933 clct[300, 300, 300, 300] lr 0.100000 26.895sec(train) 1.942sec(infer)\n",
            "Epoch 144 tst: l 0.233 a 0.934 clct[50, 50, 50, 50] 0.338sec\n",
            "Epoch 145 tr: l 0.220 a 0.934 clct[300, 300, 300, 300] lr 0.100000 27.027sec(train) 1.945sec(infer)\n",
            "Epoch 145 tst: l 0.231 a 0.934 clct[50, 50, 50, 50] 0.334sec\n",
            "Epoch 146 tr: l 0.223 a 0.933 clct[300, 300, 300, 300] lr 0.100000 26.882sec(train) 2.659sec(infer)\n",
            "Epoch 146 tst: l 0.234 a 0.933 clct[50, 50, 50, 50] 0.353sec\n",
            "Epoch 147 tr: l 0.220 a 0.934 clct[300, 300, 300, 300] lr 0.100000 28.307sec(train) 1.992sec(infer)\n",
            "Epoch 147 tst: l 0.234 a 0.934 clct[50, 50, 50, 50] 0.340sec\n",
            "Epoch 148 tr: l 0.220 a 0.934 clct[300, 300, 300, 300] lr 0.100000 27.819sec(train) 2.193sec(infer)\n",
            "Epoch 148 tst: l 0.234 a 0.934 clct[50, 50, 50, 50] 0.442sec\n",
            "Epoch 149 tr: l 0.219 a 0.934 clct[300, 300, 300, 300] lr 0.100000 27.728sec(train) 1.940sec(infer)\n",
            "Epoch 149 tst: l 0.231 a 0.934 clct[50, 50, 50, 50] 0.336sec\n",
            "Epoch 150 tr: l 0.218 a 0.934 clct[300, 300, 300, 300] lr 0.100000 27.332sec(train) 1.990sec(infer)\n",
            "Epoch 150 tst: l 0.230 a 0.935 clct[50, 50, 50, 50] 0.317sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 151 tr: l 0.217 a 0.935 clct[300, 300, 300, 300] lr 0.100000 27.249sec(train) 2.626sec(infer)\n",
            "Epoch 151 tst: l 0.231 a 0.935 clct[50, 50, 50, 50] 0.337sec\n",
            "Epoch 152 tr: l 0.215 a 0.936 clct[300, 300, 300, 300] lr 0.100000 27.250sec(train) 1.956sec(infer)\n",
            "Epoch 152 tst: l 0.229 a 0.935 clct[50, 50, 50, 50] 0.325sec\n",
            "Epoch 153 tr: l 0.217 a 0.935 clct[300, 300, 300, 300] lr 0.100000 27.129sec(train) 1.948sec(infer)\n",
            "Epoch 153 tst: l 0.230 a 0.935 clct[50, 50, 50, 50] 0.326sec\n",
            "Epoch 154 tr: l 0.215 a 0.935 clct[300, 300, 300, 300] lr 0.100000 28.105sec(train) 2.171sec(infer)\n",
            "Epoch 154 tst: l 0.228 a 0.936 clct[50, 50, 50, 50] 0.347sec\n",
            "Epoch 155 tr: l 0.213 a 0.936 clct[300, 300, 300, 300] lr 0.100000 27.145sec(train) 1.970sec(infer)\n",
            "Epoch 155 tst: l 0.227 a 0.936 clct[50, 50, 50, 50] 0.345sec\n",
            "Epoch 156 tr: l 0.218 a 0.934 clct[300, 300, 300, 300] lr 0.100000 27.263sec(train) 2.156sec(infer)\n",
            "Epoch 156 tst: l 0.233 a 0.934 clct[50, 50, 50, 50] 0.439sec\n",
            "Epoch 157 tr: l 0.214 a 0.936 clct[300, 300, 300, 300] lr 0.100000 28.088sec(train) 1.972sec(infer)\n",
            "Epoch 157 tst: l 0.228 a 0.936 clct[50, 50, 50, 50] 0.345sec\n",
            "Epoch 158 tr: l 0.213 a 0.937 clct[300, 300, 300, 300] lr 0.100000 27.157sec(train) 1.947sec(infer)\n",
            "Epoch 158 tst: l 0.226 a 0.937 clct[50, 50, 50, 50] 0.335sec\n",
            "Epoch 159 tr: l 0.215 a 0.935 clct[300, 300, 300, 300] lr 0.100000 27.315sec(train) 2.647sec(infer)\n",
            "Epoch 159 tst: l 0.228 a 0.935 clct[50, 50, 50, 50] 0.444sec\n",
            "Epoch 160 tr: l 0.211 a 0.936 clct[300, 300, 300, 300] lr 0.100000 27.098sec(train) 1.975sec(infer)\n",
            "Epoch 160 tst: l 0.227 a 0.937 clct[50, 50, 50, 50] 0.329sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 161 tr: l 0.211 a 0.936 clct[300, 300, 300, 300] lr 0.100000 27.250sec(train) 2.009sec(infer)\n",
            "Epoch 161 tst: l 0.223 a 0.936 clct[50, 50, 50, 50] 0.333sec\n",
            "Epoch 162 tr: l 0.213 a 0.935 clct[300, 300, 300, 300] lr 0.100000 27.679sec(train) 2.244sec(infer)\n",
            "Epoch 162 tst: l 0.226 a 0.935 clct[50, 50, 50, 50] 0.347sec\n",
            "Epoch 163 tr: l 0.210 a 0.936 clct[300, 300, 300, 300] lr 0.100000 27.061sec(train) 1.963sec(infer)\n",
            "Epoch 163 tst: l 0.223 a 0.936 clct[50, 50, 50, 50] 0.319sec\n",
            "Epoch 164 tr: l 0.208 a 0.937 clct[300, 300, 300, 300] lr 0.100000 27.419sec(train) 2.057sec(infer)\n",
            "Epoch 164 tst: l 0.221 a 0.937 clct[50, 50, 50, 50] 0.444sec\n",
            "Epoch 165 tr: l 0.211 a 0.936 clct[300, 300, 300, 300] lr 0.100000 27.986sec(train) 1.972sec(infer)\n",
            "Epoch 165 tst: l 0.224 a 0.936 clct[50, 50, 50, 50] 0.334sec\n",
            "Epoch 166 tr: l 0.208 a 0.937 clct[300, 300, 300, 300] lr 0.100000 27.130sec(train) 1.933sec(infer)\n",
            "Epoch 166 tst: l 0.220 a 0.937 clct[50, 50, 50, 50] 0.339sec\n",
            "Epoch 167 tr: l 0.206 a 0.938 clct[300, 300, 300, 300] lr 0.100000 27.214sec(train) 2.350sec(infer)\n",
            "Epoch 167 tst: l 0.219 a 0.938 clct[50, 50, 50, 50] 0.488sec\n",
            "Epoch 168 tr: l 0.250 a 0.922 clct[300, 300, 300, 300] lr 0.100000 27.899sec(train) 1.971sec(infer)\n",
            "Epoch 168 tst: l 0.273 a 0.922 clct[50, 50, 50, 50] 0.340sec\n",
            "Epoch 169 tr: l 0.208 a 0.937 clct[300, 300, 300, 300] lr 0.100000 28.908sec(train) 2.047sec(infer)\n",
            "Epoch 169 tst: l 0.222 a 0.937 clct[50, 50, 50, 50] 0.340sec\n",
            "Epoch 170 tr: l 0.205 a 0.938 clct[300, 300, 300, 300] lr 0.100000 28.724sec(train) 1.995sec(infer)\n",
            "Epoch 170 tst: l 0.220 a 0.938 clct[50, 50, 50, 50] 0.360sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 171 tr: l 0.204 a 0.938 clct[300, 300, 300, 300] lr 0.100000 27.617sec(train) 1.954sec(infer)\n",
            "Epoch 171 tst: l 0.218 a 0.938 clct[50, 50, 50, 50] 0.340sec\n",
            "Epoch 172 tr: l 0.205 a 0.938 clct[300, 300, 300, 300] lr 0.100000 27.745sec(train) 2.564sec(infer)\n",
            "Epoch 172 tst: l 0.221 a 0.937 clct[50, 50, 50, 50] 0.342sec\n",
            "Epoch 173 tr: l 0.204 a 0.938 clct[300, 300, 300, 300] lr 0.100000 27.884sec(train) 2.014sec(infer)\n",
            "Epoch 173 tst: l 0.219 a 0.937 clct[50, 50, 50, 50] 0.341sec\n",
            "Epoch 174 tr: l 0.201 a 0.939 clct[300, 300, 300, 300] lr 0.100000 27.652sec(train) 2.215sec(infer)\n",
            "Epoch 174 tst: l 0.216 a 0.938 clct[50, 50, 50, 50] 0.450sec\n",
            "Epoch 175 tr: l 0.205 a 0.938 clct[300, 300, 300, 300] lr 0.100000 28.301sec(train) 1.980sec(infer)\n",
            "Epoch 175 tst: l 0.219 a 0.937 clct[50, 50, 50, 50] 0.353sec\n",
            "Epoch 176 tr: l 0.204 a 0.938 clct[300, 300, 300, 300] lr 0.100000 27.333sec(train) 1.980sec(infer)\n",
            "Epoch 176 tst: l 0.220 a 0.938 clct[50, 50, 50, 50] 0.326sec\n",
            "Epoch 177 tr: l 0.204 a 0.939 clct[300, 300, 300, 300] lr 0.100000 27.852sec(train) 2.579sec(infer)\n",
            "Epoch 177 tst: l 0.219 a 0.939 clct[50, 50, 50, 50] 0.336sec\n",
            "Epoch 178 tr: l 0.203 a 0.939 clct[300, 300, 300, 300] lr 0.100000 27.479sec(train) 1.993sec(infer)\n",
            "Epoch 178 tst: l 0.218 a 0.938 clct[50, 50, 50, 50] 0.336sec\n",
            "Epoch 179 tr: l 0.200 a 0.940 clct[300, 300, 300, 300] lr 0.100000 27.457sec(train) 1.958sec(infer)\n",
            "Epoch 179 tst: l 0.216 a 0.940 clct[50, 50, 50, 50] 0.388sec\n",
            "Epoch 180 tr: l 0.201 a 0.939 clct[300, 300, 300, 300] lr 0.100000 28.466sec(train) 1.986sec(infer)\n",
            "Epoch 180 tst: l 0.218 a 0.938 clct[50, 50, 50, 50] 0.340sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 181 tr: l 0.199 a 0.940 clct[300, 300, 300, 300] lr 0.100000 27.335sec(train) 1.989sec(infer)\n",
            "Epoch 181 tst: l 0.216 a 0.939 clct[50, 50, 50, 50] 0.347sec\n",
            "Epoch 182 tr: l 0.213 a 0.934 clct[300, 300, 300, 300] lr 0.100000 27.942sec(train) 2.575sec(infer)\n",
            "Epoch 182 tst: l 0.230 a 0.934 clct[50, 50, 50, 50] 0.336sec\n",
            "Epoch 183 tr: l 0.197 a 0.940 clct[300, 300, 300, 300] lr 0.100000 27.272sec(train) 1.978sec(infer)\n",
            "Epoch 183 tst: l 0.213 a 0.940 clct[50, 50, 50, 50] 0.347sec\n",
            "Epoch 184 tr: l 0.197 a 0.940 clct[300, 300, 300, 300] lr 0.100000 28.365sec(train) 2.361sec(infer)\n",
            "Epoch 184 tst: l 0.213 a 0.940 clct[50, 50, 50, 50] 0.470sec\n",
            "Epoch 185 tr: l 0.198 a 0.940 clct[300, 300, 300, 300] lr 0.100000 28.689sec(train) 2.032sec(infer)\n",
            "Epoch 185 tst: l 0.214 a 0.940 clct[50, 50, 50, 50] 0.354sec\n",
            "Epoch 186 tr: l 0.194 a 0.941 clct[300, 300, 300, 300] lr 0.100000 28.426sec(train) 2.043sec(infer)\n",
            "Epoch 186 tst: l 0.210 a 0.941 clct[50, 50, 50, 50] 0.415sec\n",
            "Epoch 187 tr: l 0.195 a 0.941 clct[300, 300, 300, 300] lr 0.100000 29.349sec(train) 2.069sec(infer)\n",
            "Epoch 187 tst: l 0.210 a 0.941 clct[50, 50, 50, 50] 0.347sec\n",
            "Epoch 188 tr: l 0.194 a 0.941 clct[300, 300, 300, 300] lr 0.100000 28.645sec(train) 2.113sec(infer)\n",
            "Epoch 188 tst: l 0.210 a 0.940 clct[50, 50, 50, 50] 0.368sec\n",
            "Epoch 189 tr: l 0.197 a 0.940 clct[300, 300, 300, 300] lr 0.100000 28.993sec(train) 2.015sec(infer)\n",
            "Epoch 189 tst: l 0.213 a 0.940 clct[50, 50, 50, 50] 0.329sec\n",
            "Epoch 190 tr: l 0.196 a 0.940 clct[300, 300, 300, 300] lr 0.100000 27.844sec(train) 2.009sec(infer)\n",
            "Epoch 190 tst: l 0.213 a 0.939 clct[50, 50, 50, 50] 0.362sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n",
            "Epoch 191 tr: l 0.194 a 0.941 clct[300, 300, 300, 300] lr 0.100000 28.518sec(train) 2.358sec(infer)\n",
            "Epoch 191 tst: l 0.209 a 0.940 clct[50, 50, 50, 50] 0.336sec\n",
            "Epoch 192 tr: l 0.197 a 0.940 clct[300, 300, 300, 300] lr 0.100000 28.014sec(train) 2.028sec(infer)\n",
            "Epoch 192 tst: l 0.213 a 0.939 clct[50, 50, 50, 50] 0.328sec\n",
            "Epoch 193 tr: l 0.193 a 0.941 clct[300, 300, 300, 300] lr 0.100000 28.300sec(train) 2.622sec(infer)\n",
            "Epoch 193 tst: l 0.210 a 0.940 clct[50, 50, 50, 50] 0.433sec\n",
            "Epoch 194 tr: l 0.191 a 0.942 clct[300, 300, 300, 300] lr 0.100000 27.913sec(train) 2.029sec(infer)\n",
            "Epoch 194 tst: l 0.208 a 0.940 clct[50, 50, 50, 50] 0.340sec\n",
            "Epoch 195 tr: l 0.192 a 0.941 clct[300, 300, 300, 300] lr 0.100000 27.787sec(train) 2.040sec(infer)\n",
            "Epoch 195 tst: l 0.211 a 0.940 clct[50, 50, 50, 50] 0.336sec\n",
            "Epoch 196 tr: l 0.190 a 0.942 clct[300, 300, 300, 300] lr 0.100000 28.750sec(train) 2.002sec(infer)\n",
            "Epoch 196 tst: l 0.209 a 0.941 clct[50, 50, 50, 50] 0.349sec\n",
            "Epoch 197 tr: l 0.189 a 0.943 clct[300, 300, 300, 300] lr 0.100000 27.825sec(train) 2.036sec(infer)\n",
            "Epoch 197 tst: l 0.207 a 0.942 clct[50, 50, 50, 50] 0.337sec\n",
            "Epoch 198 tr: l 0.190 a 0.943 clct[300, 300, 300, 300] lr 0.100000 28.729sec(train) 2.458sec(infer)\n",
            "Epoch 198 tst: l 0.207 a 0.942 clct[50, 50, 50, 50] 0.338sec\n",
            "Epoch 199 tr: l 0.188 a 0.943 clct[300, 300, 300, 300] lr 0.100000 27.764sec(train) 2.002sec(infer)\n",
            "Epoch 199 tst: l 0.203 a 0.942 clct[50, 50, 50, 50] 0.352sec\n",
            "result written at content/results.pickle\n",
            "checkpoint written at content/checkpoint.pt\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'module' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-9e2a0388c47e>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainMNISTCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---train cluster Ended in %0.2f hour (%.3f sec) \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-e5c82c83d1e6>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'checkpoint written at {self.checkpoint_fname}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "config = get_config()\n",
        "\n",
        "config['train_seed'] = config['data_seed']\n",
        "\n",
        "print(\"config:\",config)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "exp = TrainMNISTCluster(config, device)\n",
        "exp.setup()\n",
        "exp.run()\n",
        "duration = (time.time() - start_time)\n",
        "print(\"---train cluster Ended in %0.2f hour (%.3f sec) \" % (duration/float(3600), duration))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deep_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
