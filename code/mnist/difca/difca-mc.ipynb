{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "OHJWesKs-tqd"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import itertools\n",
        "import pickle\n",
        "import copy\n",
        "import random\n",
        "import math\n",
        "import random\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from util import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAghP_o0-tqe"
      },
      "source": [
        "Reads Config file and prepares the arguments you can choose in the config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "BbUZJ2E--tqe"
      },
      "outputs": [],
      "source": [
        "LR_DECAY = False\n",
        "def get_config():\n",
        "\n",
        "    # read config json and update the sysarg\n",
        "    with open(\"config.json\", \"r\") as read_file:\n",
        "        config = json.load(read_file)\n",
        "\n",
        "    if config[\"config_override\"] == \"\":\n",
        "        del config['config_override']\n",
        "    else:\n",
        "        print(config['config_override'])\n",
        "        config_override = json.loads(config['config_override'])\n",
        "        del config['config_override']\n",
        "        config.update(config_override)\n",
        "\n",
        "    return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-J1YEoM-tqe"
      },
      "source": [
        "Class SimpleLinear with simple MLP for MNIST Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "id5Wyt-V-tqf"
      },
      "outputs": [],
      "source": [
        "class SimpleLinear(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, h1=2048):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(28*28, h1)\n",
        "        self.fc2 = torch.nn.Linear(h1, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # x = F.sigmoid(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    # def weight(self):\n",
        "    #     return self.linear1.weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qFBH01M-tqf"
      },
      "source": [
        "Class TrainMNISTCluster with all the methods needed to run the experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkGiGQ2G-tqf"
      },
      "outputs": [],
      "source": [
        "class TrainMNISTCluster(object):\n",
        "    def __init__(self, config, device):\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        assert self.config['m'] % self.config['p'] == 0\n",
        "\n",
        "    def setup(self):\n",
        "\n",
        "        os.makedirs(self.config['project_dir'], exist_ok = True)\n",
        "\n",
        "        self.result_fname = os.path.join(self.config['project_dir'], 'results.pickle')\n",
        "        self.checkpoint_fname = os.path.join(self.config['project_dir'], 'checkpoint.pt')\n",
        "\n",
        "        self.setup_datasets()\n",
        "        self.setup_models()\n",
        "\n",
        "        self.epoch = None\n",
        "        self.lr = None\n",
        "\n",
        "\n",
        "    def setup_datasets(self):\n",
        "\n",
        "        np.random.seed(self.config['data_seed'])\n",
        "\n",
        "        # generate indices for each dataset\n",
        "        # also write cluster info\n",
        "\n",
        "        MNIST_TRAINSET_DATA_SIZE = 60000\n",
        "        MNIST_TESTSET_DATA_SIZE = 10000\n",
        "\n",
        "        np.random.seed(self.config['data_seed'])\n",
        "\n",
        "        cfg = self.config\n",
        "\n",
        "        self.dataset = {}\n",
        "\n",
        "        if cfg['uneven'] == True:\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset_random_n(MNIST_TRAINSET_DATA_SIZE, cfg['p'], cfg['m'], cfg['n'])\n",
        "            (X, y) = self._load_MNIST(train=True)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['train'] = dataset\n",
        "\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset_random_n(MNIST_TESTSET_DATA_SIZE, cfg['p'], cfg['m_test'], cfg['n'])\n",
        "            (X, y) = self._load_MNIST(train=False)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['test'] = dataset\n",
        "\n",
        "        else:\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset(MNIST_TRAINSET_DATA_SIZE, cfg['p'], cfg['m'], cfg['n'])\n",
        "            (X, y) = self._load_MNIST(train=True)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['train'] = dataset\n",
        "\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset(MNIST_TESTSET_DATA_SIZE, cfg['p'], cfg['m_test'], cfg['n'])\n",
        "            (X, y) = self._load_MNIST(train=False)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['test'] = dataset\n",
        "\n",
        "        # Calculate the total count of each cluster\n",
        "        cluster_counts = {i: 0 for i in range(cfg['p'])}\n",
        "        for assign in self.dataset['train']['cluster_assign']:\n",
        "            for cluster in assign:\n",
        "                cluster_counts[cluster] += 1\n",
        "\n",
        "        self.dataset['train']['cluster'] = cluster_counts\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def _setup_dataset_random_n(self, num_data, p, m, n):\n",
        "\n",
        "        print(\"m:\",m)\n",
        "        print(\"p:\",p)\n",
        "        print(\"num_data:\",num_data)\n",
        "\n",
        "        dataset = {}\n",
        "\n",
        "        cfg = self.config\n",
        "\n",
        "        data_indices = []\n",
        "        cluster_assign = [[] for _ in range(m)]\n",
        "\n",
        "        m_per_cluster = m // p\n",
        "\n",
        "        for p_i in range(p):\n",
        "\n",
        "            ll = list(np.random.permutation(num_data))\n",
        "\n",
        "            ll2 = chunkify_uneven(ll, m_per_cluster) # splits ll into m lists\n",
        "            data_indices += ll2\n",
        "\n",
        "            for i in range(m_per_cluster):\n",
        "                cluster_assign[p_i * m_per_cluster + i].append(p_i)\n",
        "\n",
        "        for m_i in range(m):\n",
        "            p_i_ = cluster_assign[m_i]\n",
        "            for i in range(cfg['k\\'']):\n",
        "                if random.random() < 0.2:  # 20% chance\n",
        "                    if i + p_i_[0] > 3:\n",
        "                        cluster_assign[m_i].append(0)\n",
        "                    else:\n",
        "                        cluster_assign[m_i].append(p_i_[0] + i)\n",
        "\n",
        "        data_indices = np.array(data_indices, dtype=object)\n",
        "        # cluster_assign = np.array(cluster_assign, dtype=object)\n",
        "        #assert data_indices.shape[0] == cluster_assign.shape[0]\n",
        "        # assert data_indices.shape[0] == m\n",
        "\n",
        "\n",
        "        return data_indices, cluster_assign\n",
        "\n",
        "\n",
        "    def _load_MNIST(self, train=True):\n",
        "        transforms = torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               # torchvision.transforms.Normalize(\n",
        "                               #   (0.1307,), (0.3081,))\n",
        "                             ])\n",
        "        if train:\n",
        "            mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms)\n",
        "        else:\n",
        "            mnist_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms)\n",
        "\n",
        "        dl = DataLoader(mnist_dataset)\n",
        "\n",
        "        X = dl.dataset.data # (60000,28, 28)\n",
        "        y = dl.dataset.targets #(60000)\n",
        "\n",
        "        # normalize to have 0 ~ 1 range in each pixel\n",
        "\n",
        "        X = X / 255.0\n",
        "        X = X.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "    # Need p models for each client\n",
        "\n",
        "    def setup_models(self):\n",
        "        np.random.seed(self.config['train_seed'])\n",
        "        torch.manual_seed(self.config['train_seed'])\n",
        "\n",
        "        p = self.config['p']\n",
        "\n",
        "        self.models = [ SimpleLinear(h1 = self.config['h1']).to(self.device) for p_i in range(p)] # p models with p different params of dimension(1,d)\n",
        "\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        num_epochs = self.config['num_epochs']\n",
        "        lr = self.config['lr']\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # epoch -1\n",
        "        self.epoch = -1\n",
        "\n",
        "        result = {}\n",
        "        result['epoch'] = -1\n",
        "\n",
        "        t0 = time.time()\n",
        "        res = self.test(train=True)\n",
        "        t1 = time.time()\n",
        "        res['infer_time'] = t1-t0\n",
        "        result['train'] = res\n",
        "\n",
        "        self.print_epoch_stats(res)\n",
        "\n",
        "        t0 = time.time()\n",
        "        res = self.test(train=False)\n",
        "        t1 = time.time()\n",
        "        res['infer_time'] = t1-t0\n",
        "        result['test'] = res\n",
        "        self.print_epoch_stats(res)\n",
        "        results.append(result)\n",
        "\n",
        "        # this will be used in next epoch\n",
        "        cluster_assign = result['train']['cluster_assign']\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.epoch = epoch\n",
        "\n",
        "            result = {}\n",
        "            result['epoch'] = epoch\n",
        "\n",
        "            lr = self.lr_schedule(epoch)\n",
        "            result['lr'] = lr\n",
        "\n",
        "            t0 = time.time()\n",
        "            result['train'] = self.train(cluster_assign, lr = lr)\n",
        "            t1 = time.time()\n",
        "            train_time = t1-t0\n",
        "\n",
        "            t0 = time.time()\n",
        "            res = self.test(train=True)\n",
        "            t1 = time.time()\n",
        "            res['infer_time'] = t1-t0\n",
        "            res['train_time'] = train_time\n",
        "            res['lr'] = lr\n",
        "            result['train'] = res\n",
        "\n",
        "            self.print_epoch_stats(res)\n",
        "\n",
        "            t0 = time.time()\n",
        "            res = self.test(train=False)\n",
        "            t1 = time.time()\n",
        "            res['infer_time'] = t1-t0\n",
        "            result['test'] = res\n",
        "            self.print_epoch_stats(res)\n",
        "\n",
        "            results.append(result)\n",
        "\n",
        "            # this will be used in next epoch's gradient update\n",
        "            cluster_assign = result['train']['cluster_assign']\n",
        "\n",
        "            if epoch % 10 == 0 or epoch == num_epochs - 1 :\n",
        "                with open(self.result_fname, 'wb') as outfile:\n",
        "                    pickle.dump(results, outfile)\n",
        "                    print(f'result written at {self.result_fname}')\n",
        "                self.save_checkpoint()\n",
        "                print(f'checkpoint written at {self.checkpoint_fname}')\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.plot([r['train']['loss'] for r in results], label='train')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('loss')\n",
        "        plt.title('Training Loss per Epoch')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(self.config['project_dir'], 'train_loss.png'))\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.plot([r['test']['acc'] for r in results], label='train')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('test accuracy')\n",
        "        plt.title('Test Accuracy per Epoch')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(self.config['project_dir'], 'test_acc.png'))\n",
        "\n",
        "\n",
        "    def lr_schedule(self, epoch):\n",
        "        if self.lr is None:\n",
        "            self.lr = self.config['lr']\n",
        "\n",
        "        if epoch % 50 == 0 and epoch != 0 and LR_DECAY:\n",
        "            self.lr = self.lr * 0.1\n",
        "\n",
        "        return self.lr\n",
        "\n",
        "\n",
        "    def print_epoch_stats(self, res):\n",
        "        if res['is_train']:\n",
        "            data_str = 'tr'\n",
        "        else:\n",
        "            data_str = 'tst'\n",
        "\n",
        "        if 'train_time' in res:\n",
        "            time_str = f\"{res['train_time']:.3f}sec(train) {res['infer_time']:.3f}sec(infer)\"\n",
        "        else:\n",
        "            time_str = f\"{res['infer_time']:.3f}sec\"\n",
        "\n",
        "        if 'lr' in res:\n",
        "            lr_str = f\" lr {res['lr']:4f}\"\n",
        "        else:\n",
        "            lr_str = \"\"\n",
        "\n",
        "        str0 = f\"Epoch {self.epoch} {data_str}: l {res['loss']:.3f} a {res['acc']:.3f} clct{res['cl_ct']}{lr_str} {time_str}\"\n",
        "\n",
        "        print(str0)\n",
        "\n",
        "        print(self.dataset['train']['cluster'])\n",
        "\n",
        "    def train(self, cluster_assign, lr):\n",
        "        VERBOSE = 0\n",
        "\n",
        "        cfg = self.config\n",
        "        m = cfg['m']\n",
        "        p = cfg['p']\n",
        "        tau = cfg['tau']\n",
        "\n",
        "        # run local update\n",
        "        t0 = time.time()\n",
        "\n",
        "\n",
        "        updated_models = [[None for _ in range(p)] for _ in range(m)]\n",
        "        for m_i in range(m):\n",
        "            if VERBOSE and m_i % 100 == 0: print(f'm {m_i}/{m} processing \\r', end ='')\n",
        "\n",
        "            (X, y) = self.load_data(m_i)\n",
        "\n",
        "            for p_i in cluster_assign[m_i]:\n",
        "\n",
        "                model = copy.deepcopy(self.models[p_i])\n",
        "\n",
        "                # LOCAL UPDATE PER MACHINE tau times\n",
        "                for step_i in range(tau):\n",
        "\n",
        "                    y_logit = model(X)\n",
        "                    loss = self.criterion(y_logit, y)\n",
        "\n",
        "                    model.zero_grad()\n",
        "                    loss.backward()\n",
        "                    self.local_param_update(model, lr)\n",
        "\n",
        "                model.zero_grad()\n",
        "\n",
        "                updated_models[m_i][p_i] = model\n",
        "\n",
        "        t02 = time.time()\n",
        "        # print(f'running single ..took {t02-t01:.3f}sec')\n",
        "\n",
        "\n",
        "        t1 = time.time()\n",
        "        if VERBOSE: print(f'local update {t1-t0:.3f}sec')\n",
        "\n",
        "        # apply gradient update\n",
        "        t0 = time.time()\n",
        "\n",
        "        # CLUSTER MACHINES INTO p_i's\n",
        "        local_models = [[] for p_i in range(p)]\n",
        "        for m_i in range(m):\n",
        "            for p_i in cluster_assign[m_i]:\n",
        "                local_models[p_i].append(updated_models[m_i][p_i])\n",
        "\n",
        "        # NEEDS TO BE DECENTRALIZED\n",
        "        for p_i, models in enumerate(local_models):\n",
        "            if len(models) > 0:\n",
        "                self.dec_param_update(models, self.models[p_i])\n",
        "        t1 = time.time()\n",
        "\n",
        "        if VERBOSE: print(f'global update {t1-t0:.3f}sec')\n",
        "\n",
        "    def check_local_model_loss(self, local_models):\n",
        "        # for debugging\n",
        "        m = self.config['m']\n",
        "\n",
        "        losses = []\n",
        "        for m_i in range(m):\n",
        "            (X, y) = self.load_data(m_i)\n",
        "            y_logit = local_models[m_i](X)\n",
        "            loss = self.criterion(y_logit, y)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        return np.array(losses)\n",
        "\n",
        "\n",
        "    def get_inference_stats(self, train = True):\n",
        "        cfg = self.config\n",
        "        if train:\n",
        "            m = cfg['m']\n",
        "            dataset = self.dataset['train']\n",
        "        else:\n",
        "            m = cfg['m_test']\n",
        "            dataset = self.dataset['test']\n",
        "\n",
        "        p = cfg['p']\n",
        "\n",
        "\n",
        "        num_data = 0\n",
        "        tot = 0\n",
        "        losses = {}\n",
        "        corrects = {}\n",
        "        for m_i in range(m):\n",
        "            (X, y) = self.load_data(m_i, train=train) # load batch data rotated\n",
        "\n",
        "            for p_i in range(p):\n",
        "                y_logit = self.models[p_i](X)\n",
        "                loss = self.criterion(y_logit, y) # loss of\n",
        "                n_correct = self.n_correct(y_logit, y)\n",
        "\n",
        "                # if torch.isnan(loss):\n",
        "                #     print(\"nan loss: \", dataset['data_indices'][m_i])\n",
        "\n",
        "                losses[(m_i,p_i)] = loss.item()\n",
        "                corrects[(m_i,p_i)] = n_correct\n",
        "\n",
        "            # print(\"End Size: \", X.shape[0])\n",
        "            num_data += X.shape[0]\n",
        "\n",
        "        # calculate loss and cluster the machines\n",
        "        cluster_assign = [[] for _ in range(m)]\n",
        "        for m_i in range(m):\n",
        "            machine_losses = [ losses[(m_i,p_i)] for p_i in range(p) ]\n",
        "            min_p_i = np.argmin(machine_losses)\n",
        "            cp_machine_losses = copy.deepcopy(machine_losses)\n",
        "            # cp_machine_losses.pop(min_p_i)\n",
        "            # sec_min_p_i = np.argmin(cp_machine_losses)\n",
        "            # rho = (machine_losses[min_p_i] + 0.8*(abs(machine_losses[min_p_i] - machine_losses[sec_min_p_i])))\n",
        "            rho = machine_losses[min_p_i] + np.std(machine_losses)*1.1\n",
        "            cnt = 0\n",
        "            while cnt < 2:\n",
        "                argmin = np.argmin(cp_machine_losses)\n",
        "                # if cnt != 0:\n",
        "                #     print(\"rho: \", rho)\n",
        "                #     print(\"argmin: \", machine_losses[argmin])\n",
        "                if machine_losses[argmin] <= rho:\n",
        "                    cluster_assign[m_i].append(argmin)\n",
        "                    cp_machine_losses.pop(argmin)\n",
        "                cnt += 1\n",
        "\n",
        "        # print(cluster_assign)\n",
        "\n",
        "        # calculate optimal model's loss, acc over all models\n",
        "        min_corrects = []\n",
        "        min_losses = []\n",
        "        for m_i, p_i_list in enumerate(cluster_assign):\n",
        "            local_losses = [losses[(m_i, p_i)] for p_i in p_i_list]\n",
        "            min_loss = np.min(local_losses)\n",
        "            min_losses.append(min_loss)\n",
        "            local_corrects = [corrects[(m_i, p_i)] for p_i in p_i_list]\n",
        "            min_correct = local_corrects[np.argmin(local_losses)]\n",
        "            min_corrects.append(min_correct)\n",
        "            \n",
        "\n",
        "        print(\"losses: \", min_losses)\n",
        "        print(\"corrects: \", np.sum(min_corrects))\n",
        "        print(\"num_data: \", num_data)\n",
        "        loss = np.mean(min_losses)\n",
        "        acc = np.sum(min_corrects) / num_data\n",
        "\n",
        "\n",
        "        # check cluster assignment acc\n",
        "        cl_acc = np.mean([set(cluster_assign[m_i]) == set(dataset['cluster_assign'][m_i]) for m_i in range(m)])\n",
        "        cl_ct = [np.sum([p_i in cluster_assign[m_i] for m_i in range(m)]) for p_i in range(p)]\n",
        "\n",
        "        res = {} # results\n",
        "        # res['losses'] = losses\n",
        "        # res['corrects'] = corrects\n",
        "        res['cluster_assign'] = cluster_assign\n",
        "        res['num_data'] = num_data\n",
        "        res['loss'] = loss\n",
        "        res['acc'] = acc\n",
        "        res['cl_acc'] = cl_acc\n",
        "        res['cl_ct'] = cl_ct\n",
        "        res['is_train'] = train\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "        return res\n",
        "\n",
        "    def n_correct(self, y_logit, y):\n",
        "        _, predicted = torch.max(y_logit.data, 1)\n",
        "        correct = (predicted == y).sum().item()\n",
        "\n",
        "        return correct\n",
        "\n",
        "    # TODO Does every Cluster get 4 clients with the same data, but rotated differently?\n",
        "\n",
        "    def load_data(self, m_i, train=True):\n",
        "        # this part is very fast since its just rearranging models\n",
        "        cfg = self.config\n",
        "\n",
        "        if train:\n",
        "            dataset = self.dataset['train']\n",
        "        else:\n",
        "            dataset = self.dataset['test']\n",
        "\n",
        "        indices = dataset['data_indices'][m_i]\n",
        "        p_i = dataset['cluster_assign'][m_i]\n",
        "\n",
        "        X_batch = dataset['X'][indices]\n",
        "        y_batch = dataset['y'][indices]\n",
        "\n",
        "        # k : how many times rotate 90 degree\n",
        "        # k =1 : 90 , k=2 180, k=3 270\n",
        "        if cfg['p'] == 4:\n",
        "            k = p_i[0]\n",
        "        elif cfg['p'] == 2:\n",
        "            k = (p_i[0] % 2) * 2\n",
        "        elif cfg['p'] == 1:\n",
        "            k = 0\n",
        "        else:\n",
        "            raise NotImplementedError(\"only p=1,2,4 supported\")\n",
        "\n",
        "        X_batch2 = torch.rot90(X_batch, k=int(k), dims=(1, 2))\n",
        "        X_batch3 = X_batch2.reshape(-1, 28 * 28)\n",
        "\n",
        "        if len(p_i) > 1:\n",
        "            additional_X_batches = []\n",
        "            additional_y_batches = []\n",
        "\n",
        "            for p_i_ in p_i[1:]:\n",
        "                additional_rotation = p_i_ % 4\n",
        "                X_batch_additional_rot = torch.rot90(X_batch, k=additional_rotation, dims=(1, 2))\n",
        "                X_batch_additional_rot = X_batch_additional_rot.reshape(-1, 28 * 28)\n",
        "                additional_X_batches.append(X_batch_additional_rot)\n",
        "                additional_y_batches.append(y_batch)\n",
        "\n",
        "            X_batch3 = torch.cat([X_batch3] + additional_X_batches, dim=0)\n",
        "            y_batch = torch.cat([y_batch] + additional_y_batches, dim=0)\n",
        "\n",
        "        # print(\"Start Size: \", X_batch3.shape[0])\n",
        "        # print(\"Y_batch size: \", y_batch.shape[0])\n",
        "        return X_batch3, y_batch\n",
        "\n",
        "\n",
        "    def local_param_update(self, model, lr):\n",
        "\n",
        "        # gradient update manually\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                param.data -= lr * param.grad\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # import ipdb; ipdb.set_trace() # we need to check the output of name, check if duplicate exists\n",
        "\n",
        "\n",
        "    def dec_param_update(self, local_models, global_model):\n",
        "\n",
        "        num_clients = len(local_models)\n",
        "\n",
        "        if num_clients == 0:\n",
        "            return\n",
        "\n",
        "        if num_clients == 1:\n",
        "            bc_client = dict(local_models[0].named_parameters())\n",
        "            for name, param in global_model.named_parameters():\n",
        "                param.data = bc_client[name].data.clone()\n",
        "            return\n",
        "\n",
        "        max_e = 100\n",
        "        if num_clients <= max_e:\n",
        "            e = num_clients - 1\n",
        "        else:\n",
        "            e = min(max_e, int(np.log(num_clients) * 10))\n",
        "\n",
        "        if e >= num_clients:\n",
        "            e = num_clients - 1\n",
        "\n",
        "        client_indices = list(range(num_clients))\n",
        "\n",
        "        for m_i, local_model in enumerate(local_models):\n",
        "            selected_clients = random.sample([i for i in client_indices if i != m_i], e)\n",
        "\n",
        "            for m_j in selected_clients:\n",
        "\n",
        "                m_j_params = dict(local_models[m_j].named_parameters())\n",
        "\n",
        "                for name, param in local_model.named_parameters():\n",
        "                    m_i_param = param.data.clone()\n",
        "                    m_j_param = m_j_params[name].data.clone()\n",
        "                    param.data = (m_i_param + m_j_param) / 2\n",
        "\n",
        "        bc_client = random.choice(client_indices)\n",
        "        bc_client_params = dict(local_models[bc_client].named_parameters())\n",
        "        for name, param in global_model.named_parameters():\n",
        "            param.data = bc_client_params[name].data.clone()\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def test(self, train=False):\n",
        "        return self.get_inference_stats(train=train)\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        models_to_save = [model.state_dict() for model in self.models]\n",
        "        torch.save({'models':models_to_save}, self.checkpoint_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ADsUSUi-tqf"
      },
      "source": [
        "Running the Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T_XDv25r-tqf",
        "outputId": "9c8f4300-c792-4e49-be40-c694fa066e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config: {'m': 60, 'm_test': 8, 'p': 4, 'n': 4000, 'uneven': True, \"k'\": 2, 'h1': 200, 'num_epochs': 300, 'batch_size': 100, 'tau': 10, 'lr': 0.1, 'data_seed': 10, 'train_seed': 10, 'project_dir': 'output'}\n",
            "Using device: cuda\n",
            "m: 60\n",
            "p: 4\n",
            "num_data: 60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "m: 8\n",
            "p: 4\n",
            "num_data: 10000\n",
            "len:  10000\n",
            "len:  10000\n",
            "len:  10000\n",
            "len:  10000\n",
            "losses:  [2.3006935119628906, 2.294890880584717, 2.2937657833099365, 2.295325994491577, 2.3001153469085693, 2.2949016094207764, 2.294433116912842, 2.295640707015991, 2.300248861312866, 2.297391176223755, 2.295973062515259, 2.3012032508850098, 2.2944064140319824, 2.293426990509033, 2.295771837234497, 2.2960894107818604, 2.299071788787842, 2.295602560043335, 2.3003790378570557, 2.295612096786499, 2.295321464538574, 2.2950806617736816, 2.294212579727173, 2.2957589626312256, 2.295563220977783, 2.2996180057525635, 2.295206308364868, 2.2930591106414795, 2.2946741580963135, 2.296783924102783, 2.3021302223205566, 2.3013155460357666, 2.2991883754730225, 2.298238515853882, 2.302853584289551, 2.2982048988342285, 2.301661968231201, 2.2977969646453857, 2.2979042530059814, 2.294034004211426, 2.2967276573181152, 2.3010129928588867, 2.2995522022247314, 2.2995285987854004, 2.3003485202789307, 2.3012187480926514, 2.3020243644714355, 2.299201488494873, 2.3041627407073975, 2.3009934425354004, 2.299065589904785, 2.302501916885376, 2.300102949142456, 2.302891492843628, 2.3043878078460693, 2.303942918777466, 2.3031766414642334, 2.3003828525543213, 2.2995026111602783, 2.3022873401641846]\n",
            "corrects:  36510\n",
            "num_data:  348061\n",
            "Epoch -1 tr: l 2.298 a 0.105 clct[28, 29, 8, 17] 0.411sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [2.296266555786133, 2.2943577766418457, 2.2941925525665283, 2.295534133911133, 2.2980763912200928, 2.2960801124572754, 2.300595283508301, 2.3020803928375244]\n",
            "corrects:  5117\n",
            "num_data:  46733\n",
            "Epoch -1 tst: l 2.297 a 0.109 clct[3, 5, 1, 2] 0.058sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [2.1973319053649902, 2.1878395080566406, 2.1840994358062744, 2.1846156120300293, 2.194856882095337, 2.184384822845459, 2.1846811771392822, 2.186610460281372, 2.2174065113067627, 2.191631317138672, 2.1870338916778564, 2.191715717315674, 2.1841015815734863, 2.180889368057251, 2.1869380474090576, 2.102978229522705, 2.162428140640259, 2.1037988662719727, 2.191732406616211, 2.1025187969207764, 2.106175661087036, 2.1038386821746826, 2.106722593307495, 2.1025097370147705, 2.105565071105957, 2.1933534145355225, 2.103076934814453, 2.0898537635803223, 2.102555513381958, 2.108207941055298, 2.182436227798462, 2.1034915447235107, 2.106077194213867, 2.0959255695343018, 2.104048252105713, 2.102524757385254, 2.0990793704986572, 2.104201555252075, 2.1037662029266357, 2.09883189201355, 2.1108815670013428, 2.0974838733673096, 2.104846715927124, 2.1022253036499023, 2.103243112564087, 2.1919991970062256, 2.194397449493408, 2.1908657550811768, 2.1972429752349854, 2.193687915802002, 2.1867029666900635, 2.1951801776885986, 2.189833402633667, 2.1959455013275146, 2.1970794200897217, 2.198092460632324, 2.196183443069458, 2.1938700675964355, 2.1945769786834717, 2.1963508129119873]\n",
            "corrects:  167054\n",
            "num_data:  348061\n",
            "Epoch 0 tr: l 2.153 a 0.480 clct[30, 15, 16, 18] lr 0.100000 1.706sec(train) 0.347sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [2.1866884231567383, 2.1822659969329834, 2.100722074508667, 2.0993361473083496, 2.098034381866455, 2.099562406539917, 2.1941001415252686, 2.193301200866699]\n",
            "corrects:  24919\n",
            "num_data:  46733\n",
            "Epoch 0 tst: l 2.144 a 0.533 clct[4, 2, 2, 2] 0.051sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "result written at output\\results.pickle\n",
            "checkpoint written at output\\checkpoint.pt\n",
            "losses:  [2.0459253787994385, 2.0989558696746826, 2.090458631515503, 2.0902364253997803, 2.0451838970184326, 2.0908565521240234, 2.090646982192993, 2.0958757400512695, 2.118093490600586, 2.1021714210510254, 2.0949950218200684, 2.0415191650390625, 2.0916919708251953, 2.084512710571289, 2.095921754837036, 1.8202486038208008, 1.9666624069213867, 1.8276176452636719, 2.042490005493164, 1.8197840452194214, 1.825378179550171, 1.8216780424118042, 1.8015029430389404, 1.820249319076538, 1.8249698877334595, 2.045395612716675, 1.821588397026062, 1.7989712953567505, 1.8201053142547607, 1.8185663223266602, 2.0265800952911377, 1.8206870555877686, 1.8226988315582275, 1.8018661737442017, 1.817333698272705, 1.8141050338745117, 1.8129101991653442, 1.8159480094909668, 1.816430687904358, 1.7645915746688843, 1.8303762674331665, 1.8062770366668701, 1.816493272781372, 1.809239387512207, 1.816918969154358, 2.0041422843933105, 2.006269693374634, 2.0527968406677246, 2.0120632648468018, 2.005274772644043, 2.0536558628082275, 2.0078482627868652, 2.050212860107422, 2.0101983547210693, 2.010831117630005, 2.010509967803955, 2.009382486343384, 2.008985757827759, 2.0095982551574707, 2.0132384300231934]\n",
            "corrects:  200407\n",
            "num_data:  348061\n",
            "Epoch 1 tr: l 1.947 a 0.576 clct[30, 15, 16, 19] lr 0.100000 1.928sec(train) 0.338sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [2.0924060344696045, 2.087641954421997, 1.8134325742721558, 1.8126143217086792, 1.8038452863693237, 1.8069674968719482, 2.004096269607544, 2.003502130508423]\n",
            "corrects:  30038\n",
            "num_data:  46733\n",
            "Epoch 1 tst: l 1.928 a 0.643 clct[4, 2, 2, 2] 0.052sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.883005976676941, 2.0366017818450928, 2.0242130756378174, 2.024369239807129, 1.88704252243042, 2.025346040725708, 2.023253917694092, 2.030914783477783, 2.0101959705352783, 2.040600061416626, 2.0311105251312256, 1.8808013200759888, 2.0243756771087646, 2.015817165374756, 2.0303173065185547, 1.5037978887557983, 1.745580792427063, 1.5152077674865723, 1.8722715377807617, 1.5012787580490112, 1.5114039182662964, 1.5034008026123047, 1.440603256225586, 1.5038435459136963, 1.5084322690963745, 1.8740469217300415, 1.5033241510391235, 1.4710040092468262, 1.5021288394927979, 1.5102250576019287, 1.8508895635604858, 1.4773863554000854, 1.4824752807617188, 1.4550410509109497, 1.4747356176376343, 1.4720373153686523, 1.4699660539627075, 1.4712276458740234, 1.4754716157913208, 1.4154736995697021, 1.498719573020935, 1.461065411567688, 1.4709361791610718, 1.4643781185150146, 1.4750704765319824, 1.6957497596740723, 1.6962058544158936, 1.8667457103729248, 1.7076435089111328, 1.6965341567993164, 1.8628979921340942, 1.7004748582839966, 1.8629685640335083, 1.7019543647766113, 1.7048674821853638, 1.6999894380569458, 1.7042286396026611, 1.7040568590164185, 1.699549913406372, 1.7092821598052979]\n",
            "corrects:  210858\n",
            "num_data:  348061\n",
            "Epoch 2 tr: l 1.698 a 0.606 clct[27, 15, 16, 19] lr 0.100000 1.988sec(train) 0.329sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [2.0270962715148926, 2.020156145095825, 1.494503378868103, 1.4893099069595337, 1.4550557136535645, 1.4604122638702393, 1.6926026344299316, 1.6879334449768066]\n",
            "corrects:  31114\n",
            "num_data:  46733\n",
            "Epoch 2 tst: l 1.666 a 0.666 clct[4, 2, 2, 2] 0.048sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.747467041015625, 1.9398454427719116, 1.9233676195144653, 1.925305962562561, 1.7499703168869019, 1.9247596263885498, 1.9201154708862305, 1.9321579933166504, 1.9120286703109741, 1.9442096948623657, 1.9316577911376953, 1.7437818050384521, 1.922559142112732, 1.912978172302246, 1.927751064300537, 1.2392381429672241, 1.551308035850525, 1.2481650114059448, 1.7129602432250977, 1.239926815032959, 1.2522461414337158, 1.2390575408935547, 1.2018611431121826, 1.2424362897872925, 1.247961163520813, 1.7148504257202148, 1.2408547401428223, 1.1990021467208862, 1.2360868453979492, 1.2540327310562134, 1.7209464311599731, 1.174413800239563, 1.1859525442123413, 1.1544244289398193, 1.1739493608474731, 1.176738977432251, 1.1663800477981567, 1.1691783666610718, 1.181452751159668, 1.1180857419967651, 1.2104451656341553, 1.1581240892410278, 1.1695917844772339, 1.1672840118408203, 1.1776076555252075, 1.4168835878372192, 1.4149794578552246, 1.6777962446212769, 1.430765151977539, 1.4160923957824707, 1.6642646789550781, 1.4230787754058838, 1.6725844144821167, 1.4237877130508423, 1.428562045097351, 1.4174799919128418, 1.4267114400863647, 1.426553726196289, 1.4188648462295532, 1.4324259757995605]\n",
            "corrects:  221148\n",
            "num_data:  348061\n",
            "Epoch 3 tr: l 1.473 a 0.635 clct[27, 15, 16, 19] lr 0.100000 1.879sec(train) 0.336sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.9257749319076538, 1.9173871278762817, 1.2293407917022705, 1.222366213798523, 1.152178406715393, 1.1603108644485474, 1.411629557609558, 1.4013726711273193]\n",
            "corrects:  32707\n",
            "num_data:  46733\n",
            "Epoch 3 tst: l 1.428 a 0.700 clct[4, 2, 2, 2] 0.049sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.6703509092330933, 1.9118211269378662, 1.8915846347808838, 1.8963291645050049, 1.6762231588363647, 1.8939493894577026, 1.8851778507232666, 1.9018276929855347, 1.8771075010299683, 1.915399432182312, 1.901734709739685, 1.667694330215454, 1.8895364999771118, 1.881360650062561, 1.8943297863006592, 1.030824065208435, 1.4104206562042236, 1.0384823083877563, 1.608680248260498, 1.031725525856018, 1.0439854860305786, 1.0290642976760864, 0.9806575179100037, 1.0331660509109497, 1.040314793586731, 1.6083942651748657, 1.0324052572250366, 0.9859473705291748, 1.025237798690796, 1.044779896736145, 1.658509373664856, 0.9724012017250061, 0.9828064441680908, 0.9508275389671326, 0.9725308418273926, 0.9756569862365723, 0.9653335213661194, 0.9593054056167603, 0.9810019731521606, 0.913428544998169, 1.0088247060775757, 0.9568246006965637, 0.9686943888664246, 0.9631605744361877, 0.9746106863021851, 1.1610556840896606, 1.1574974060058594, 1.5328530073165894, 1.1751124858856201, 1.1603407859802246, 1.515504002571106, 1.1704059839248657, 1.5284903049468994, 1.1674484014511108, 1.1749992370605469, 1.1578737497329712, 1.170730471611023, 1.171810269355774, 1.1606147289276123, 1.1785088777542114]\n",
            "corrects:  226418\n",
            "num_data:  348061\n",
            "Epoch 4 tr: l 1.308 a 0.651 clct[27, 15, 8, 19] lr 0.100000 1.616sec(train) 0.335sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.8943485021591187, 1.8859003782272339, 1.01955246925354, 1.0108963251113892, 0.9462495446205139, 0.9539589881896973, 1.1547952890396118, 1.1390072107315063]\n",
            "corrects:  33320\n",
            "num_data:  46733\n",
            "Epoch 4 tst: l 1.251 a 0.713 clct[4, 2, 0, 2] 0.050sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.640079379081726, 1.7758108377456665, 1.7514359951019287, 1.757775068283081, 1.6475472450256348, 1.753111481666565, 1.7447760105133057, 1.7622995376586914, 1.882280707359314, 1.778765082359314, 1.7617496252059937, 1.6364578008651733, 1.7485090494155884, 1.7412736415863037, 1.752848505973816, 0.8824700713157654, 1.3188155889511108, 0.8887473940849304, 1.5469775199890137, 0.8834306597709656, 0.8965541124343872, 0.8783177733421326, 0.8360165357589722, 0.8849537372589111, 0.8933576941490173, 1.5460623502731323, 0.8841893672943115, 0.8275358080863953, 0.8746342658996582, 0.8934003114700317, 1.6435770988464355, 0.8292128443717957, 0.8399766683578491, 0.8084636926651001, 0.8300129771232605, 0.8354588150978088, 0.8226098418235779, 0.8082125186920166, 0.8389424085617065, 0.774249255657196, 0.8664482831954956, 0.8079449534416199, 0.8239727020263672, 0.8219338059425354, 0.8326667547225952, 1.014056921005249, 1.008985996246338, 1.3851890563964844, 1.0278263092041016, 1.0118829011917114, 1.3690871000289917, 1.0243926048278809, 1.378263235092163, 1.0173951387405396, 1.029870867729187, 1.0097471475601196, 1.0228593349456787, 1.026042103767395, 1.0127776861190796, 1.0308772325515747]\n",
            "corrects:  234800\n",
            "num_data:  348061\n",
            "Epoch 5 tr: l 1.177 a 0.675 clct[31, 15, 8, 19] lr 0.100000 1.641sec(train) 0.330sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.7541130781173706, 1.743043303489685, 0.8702106475830078, 0.8613370656967163, 0.8036016821861267, 0.8118769526481628, 1.0061556100845337, 0.9872643351554871]\n",
            "corrects:  34695\n",
            "num_data:  46733\n",
            "Epoch 5 tst: l 1.105 a 0.742 clct[4, 2, 0, 2] 0.060sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.6139345169067383, 1.746220588684082, 1.7186729907989502, 1.7276731729507446, 1.6177988052368164, 1.721761703491211, 1.7089347839355469, 1.7299561500549316, 1.8677003383636475, 1.7483594417572021, 1.7294394969940186, 1.6084990501403809, 1.714081048965454, 1.709741234779358, 1.7166240215301514, 0.8002864718437195, 1.2214739322662354, 0.804808497428894, 1.4415295124053955, 0.8017820715904236, 0.8153992295265198, 0.7953622341156006, 0.7628475427627563, 0.8026331067085266, 0.8124096393585205, 1.4393950700759888, 0.8016725182533264, 0.7473077178001404, 0.7906436920166016, 0.8144077658653259, 1.6322407722473145, 0.7317288517951965, 0.7428846955299377, 0.7087362408638, 0.7310044169425964, 0.7408156394958496, 0.7262504696846008, 0.7098777294158936, 0.7426857948303223, 0.689701497554779, 0.7712131142616272, 0.7180944681167603, 0.7296974658966064, 0.7261679172515869, 0.7364946007728577, 0.8883206248283386, 0.883876383304596, 1.3038831949234009, 0.9017980694770813, 0.8867693543434143, 1.287155032157898, 0.9000490307807922, 1.3002173900604248, 0.8914374709129333, 0.9060159921646118, 0.8804287314414978, 0.8974063992500305, 0.9013139605522156, 0.8852870464324951, 0.9049115180969238]\n",
            "corrects:  237352\n",
            "num_data:  348061\n",
            "Epoch 6 tr: l 1.096 a 0.682 clct[31, 14, 3, 19] lr 0.100000 1.719sec(train) 0.332sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.7226083278656006, 1.7114527225494385, 0.7900235056877136, 0.7790329456329346, 0.7075077891349792, 0.7163528800010681, 0.8814133405685425, 0.859710156917572]\n",
            "corrects:  34921\n",
            "num_data:  46733\n",
            "Epoch 6 tst: l 1.021 a 0.747 clct[4, 2, 0, 2] 0.050sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.6108336448669434, 1.6158257722854614, 1.5872386693954468, 1.5978808403015137, 1.614814043045044, 1.5911824703216553, 1.5775632858276367, 1.5975590944290161, 1.8852602243423462, 1.6228063106536865, 1.5984143018722534, 1.6048935651779175, 1.5823273658752441, 1.5790992975234985, 1.581878900527954, 0.7260748744010925, 1.1678483486175537, 0.731106162071228, 1.3994141817092896, 0.728557288646698, 0.7423964738845825, 0.7214387059211731, 0.6822482347488403, 0.7294815182685852, 0.739897608757019, 1.396281123161316, 0.7277934551239014, 0.6719151139259338, 0.7164996266365051, 0.7405385375022888, 1.6136326789855957, 0.663866400718689, 0.6746517419815063, 0.6397509574890137, 0.663096010684967, 0.674565851688385, 0.6578534841537476, 0.6399101614952087, 0.6752392053604126, 0.6236180663108826, 0.7017561197280884, 0.6463099122047424, 0.6589604616165161, 0.659763753414154, 0.6692073345184326, 0.8198789358139038, 0.8156796097755432, 1.2006547451019287, 0.8332977294921875, 0.8183625936508179, 1.165831446647644, 0.8321228623390198, 1.1984457969665527, 0.821868896484375, 0.8394473791122437, 0.8109520077705383, 0.8293989896774292, 0.8346094489097595, 0.8150166869163513, 0.8362711071968079]\n",
            "corrects:  242848\n",
            "num_data:  348061\n",
            "Epoch 7 tr: l 1.020 a 0.698 clct[31, 15, 3, 19] lr 0.100000 1.741sec(train) 0.335sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.5929896831512451, 1.5800801515579224, 0.7169874906539917, 0.705938458442688, 0.6400333642959595, 0.6493528485298157, 0.8127774596214294, 0.7894573211669922]\n",
            "corrects:  35792\n",
            "num_data:  46733\n",
            "Epoch 7 tst: l 0.936 a 0.766 clct[4, 2, 0, 2] 0.049sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.6282150745391846, 1.407410979270935, 1.3758422136306763, 1.38896644115448, 1.6344126462936401, 1.3807941675186157, 1.3682252168655396, 1.3911815881729126, 1.811660647392273, 1.4091920852661133, 1.3856146335601807, 1.622094750404358, 1.3771778345108032, 1.370760440826416, 1.3706811666488647, 0.6634294390678406, 1.148442268371582, 0.6667951345443726, 1.3642388582229614, 0.6653141975402832, 0.6794744729995728, 0.658447265625, 0.6125211715698242, 0.6660094857215881, 0.6772697567939758, 1.3652111291885376, 0.6643504500389099, 0.6058303713798523, 0.6528613567352295, 0.6781238317489624, 1.62624192237854, 0.6122287511825562, 0.6231264472007751, 0.5870780944824219, 0.6117607951164246, 0.624373733997345, 0.605282187461853, 0.5877518653869629, 0.6242855787277222, 0.5854779481887817, 0.6497832536697388, 0.5967372059822083, 0.6054016947746277, 0.6095264554023743, 0.6179348230361938, 0.796002209186554, 0.7924079298973083, 1.0732587575912476, 0.8053005337715149, 0.7933021783828735, 1.0567307472229004, 0.8096898794174194, 1.0814765691757202, 0.7951342463493347, 0.8162189722061157, 0.7865737676620483, 0.8028694987297058, 0.8134156465530396, 0.7923773527145386, 0.8127557039260864]\n",
            "corrects:  249635\n",
            "num_data:  348061\n",
            "Epoch 8 tr: l 0.945 a 0.717 clct[31, 14, 4, 16] lr 0.100000 1.500sec(train) 0.333sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.381102204322815, 1.3695060014724731, 0.6544601321220398, 0.6428589820861816, 0.5892759561538696, 0.5988192558288574, 0.7903950214385986, 0.7640897631645203]\n",
            "corrects:  36913\n",
            "num_data:  46733\n",
            "Epoch 8 tst: l 0.849 a 0.790 clct[4, 2, 0, 2] 0.048sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.6677711009979248, 1.4372317790985107, 1.4063832759857178, 1.4180570840835571, 1.6766667366027832, 1.4094221591949463, 1.3938958644866943, 1.416674256324768, 1.859347939491272, 1.4423085451126099, 1.413016676902771, 1.6611289978027344, 1.4017139673233032, 1.3994053602218628, 1.395661473274231, 0.6117380261421204, 1.151977300643921, 0.6134874224662781, 1.2608951330184937, 0.6134693622589111, 0.628540575504303, 0.6065386533737183, 0.5690526962280273, 0.613584578037262, 0.6246665716171265, 1.2615724802017212, 0.6115429401397705, 0.5468356609344482, 0.6009541749954224, 0.6291666030883789, 1.4071835279464722, 0.571479082107544, 0.5823816061019897, 0.5424072742462158, 0.5712999105453491, 0.5842481255531311, 0.5652899146080017, 0.5457946062088013, 0.5843257308006287, 0.5474227070808411, 0.6067782044410706, 0.5593764185905457, 0.5674768686294556, 0.5687016248703003, 0.5766115188598633, 0.732304573059082, 0.7284818291664124, 1.0588998794555664, 0.7450297474861145, 0.728594183921814, 1.0309312343597412, 0.7455450296401978, 1.06142258644104, 0.7342351675033569, 0.7545908093452454, 0.7219390869140625, 0.7416088581085205, 0.7487644553184509, 0.728053092956543, 0.7473132014274597]\n",
            "corrects:  251329\n",
            "num_data:  348061\n",
            "Epoch 9 tr: l 0.912 a 0.722 clct[31, 14, 4, 16] lr 0.100000 1.505sec(train) 0.336sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.4131642580032349, 1.3989477157592773, 0.6033600568771362, 0.5915661454200745, 0.5492766499519348, 0.5588710308074951, 0.7261871695518494, 0.7010696530342102]\n",
            "corrects:  36891\n",
            "num_data:  46733\n",
            "Epoch 9 tst: l 0.818 a 0.789 clct[4, 2, 0, 2] 0.049sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.6898332834243774, 1.2535617351531982, 1.2260653972625732, 1.2403050661087036, 1.7011187076568604, 1.2294094562530518, 1.2143625020980835, 1.2390329837799072, 1.764994502067566, 1.2574838399887085, 1.2334717512130737, 1.6844626665115356, 1.2277125120162964, 1.2227329015731812, 1.213909387588501, 0.5727955102920532, 1.1617090702056885, 0.5724069476127625, 1.1925673484802246, 0.5745721459388733, 0.5886880159378052, 0.5668554306030273, 0.5138235092163086, 0.5745675563812256, 0.5864785313606262, 1.1910213232040405, 0.5718117356300354, 0.5098573565483093, 0.5608311295509338, 0.5897089838981628, 1.3093860149383545, 0.5392423272132874, 0.5502164363861084, 0.5107848048210144, 0.5395810604095459, 0.5535451769828796, 0.5324912071228027, 0.5125325918197632, 0.5522205233573914, 0.5172820687294006, 0.5746139287948608, 0.5261664390563965, 0.5354740619659424, 0.5383217334747314, 0.5453357100486755, 0.7349265813827515, 0.7325027585029602, 0.966465413570404, 0.7445986270904541, 0.7306749820709229, 0.9394065141677856, 0.7492635250091553, 0.9726969599723816, 0.7335686683654785, 0.7574692964553833, 0.7247297167778015, 0.7425388097763062, 0.7542169690132141, 0.7309184670448303, 0.7495653629302979]\n",
            "corrects:  257103\n",
            "num_data:  348061\n",
            "Epoch 10 tr: l 0.855 a 0.739 clct[31, 14, 16, 16] lr 0.100000 1.508sec(train) 0.331sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.2300477027893066, 1.218186616897583, 0.5645034313201904, 0.552428126335144, 0.5177125930786133, 0.5279549360275269, 0.7295776605606079, 0.7011610865592957]\n",
            "corrects:  37661\n",
            "num_data:  46733\n",
            "Epoch 10 tst: l 0.755 a 0.806 clct[4, 2, 2, 2] 0.048sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "result written at output\\results.pickle\n",
            "checkpoint written at output\\checkpoint.pt\n",
            "losses:  [1.4285428524017334, 1.2981911897659302, 1.269214153289795, 1.2832450866699219, 1.4354689121246338, 1.2730262279510498, 1.2543270587921143, 1.2795360088348389, 1.697580337524414, 1.305433988571167, 1.2758482694625854, 1.426594614982605, 1.2663325071334839, 1.263654351234436, 1.2561715841293335, 0.5745871067047119, 1.1530241966247559, 0.5732179880142212, 1.100453495979309, 0.5775355100631714, 0.5891961455345154, 0.5712555646896362, 0.4807257652282715, 0.5772696733474731, 0.5894603133201599, 1.0995944738388062, 0.5764216184616089, 0.5157248973846436, 0.5628548860549927, 0.5875161290168762, 1.268829584121704, 0.5138769745826721, 0.5253655910491943, 0.4857429265975952, 0.5145758390426636, 0.5298457741737366, 0.5066810846328735, 0.4881305992603302, 0.5283836126327515, 0.493404358625412, 0.5495147705078125, 0.4956538677215576, 0.509719967842102, 0.5153986811637878, 0.5214624404907227, 0.6766655445098877, 0.6728547811508179, 0.9581340551376343, 0.6889853477478027, 0.6734047532081604, 0.9214991331100464, 0.6913208365440369, 0.9643232226371765, 0.6778246164321899, 0.7012708187103271, 0.6657537221908569, 0.6863296627998352, 0.6953232288360596, 0.6705257296562195, 0.6918970346450806]\n",
            "corrects:  257462\n",
            "num_data:  348061\n",
            "Epoch 11 tr: l 0.827 a 0.740 clct[31, 14, 16, 17] lr 0.100000 1.705sec(train) 0.334sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.2787996530532837, 1.2639192342758179, 0.564829409122467, 0.5543937087059021, 0.4934467077255249, 0.504319965839386, 0.6711512207984924, 0.6445027589797974]\n",
            "corrects:  37490\n",
            "num_data:  46733\n",
            "Epoch 11 tst: l 0.747 a 0.802 clct[4, 2, 2, 2] 0.048sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.4894429445266724, 1.2521501779556274, 1.223987102508545, 1.2387990951538086, 1.4972658157348633, 1.227091908454895, 1.207884669303894, 1.2327120304107666, 1.7838298082351685, 1.2573442459106445, 1.2287464141845703, 1.4856282472610474, 1.221253752708435, 1.218812346458435, 1.2080693244934082, 0.5372534394264221, 1.009315013885498, 0.5345380306243896, 0.982739269733429, 0.5388787984848022, 0.5526782870292664, 0.5321929454803467, 0.46760857105255127, 0.5373048782348633, 0.550541877746582, 0.978593647480011, 0.5370970368385315, 0.47434180974960327, 0.5222302675247192, 0.5534691214561462, 1.4529448747634888, 0.4930435121059418, 0.5036265850067139, 0.46406006813049316, 0.4940367341041565, 0.5076483488082886, 0.4863452911376953, 0.46537330746650696, 0.5060946345329285, 0.466405987739563, 0.5265783667564392, 0.4773535132408142, 0.4901861250400543, 0.4930211901664734, 0.49877825379371643, 0.6562001705169678, 0.6529754996299744, 0.923068642616272, 0.6676028966903687, 0.6520552635192871, 0.8914365172386169, 0.6708589196205139, 0.9304915070533752, 0.6560841798782349, 0.6810585260391235, 0.6427975296974182, 0.6651604175567627, 0.674878716468811, 0.64982008934021, 0.668637752532959]\n",
            "corrects:  261246\n",
            "num_data:  348061\n",
            "Epoch 12 tr: l 0.802 a 0.751 clct[28, 14, 19, 16] lr 0.100000 1.732sec(train) 0.337sec(infer)\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n",
            "losses:  [1.233538031578064, 1.2178761959075928, 0.527633786201477, 0.516498327255249, 0.4717588424682617, 0.4828726053237915, 0.6512112617492676, 0.6228963732719421]\n",
            "corrects:  37870\n",
            "num_data:  46733\n",
            "Epoch 12 tst: l 0.716 a 0.810 clct[4, 2, 2, 2] 0.050sec\n",
            "{0: 23, 1: 23, 2: 23, 3: 19}\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[157], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m exp \u001b[38;5;241m=\u001b[39m TrainMNISTCluster(config, device)\n\u001b[0;32m     11\u001b[0m exp\u001b[38;5;241m.\u001b[39msetup()\n\u001b[1;32m---> 12\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m duration \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---train cluster Ended in \u001b[39m\u001b[38;5;132;01m%0.2f\u001b[39;00m\u001b[38;5;124m hour (\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m sec) \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (duration\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m3600\u001b[39m), duration))\n",
            "Cell \u001b[1;32mIn[156], line 207\u001b[0m, in \u001b[0;36mTrainMNISTCluster.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lr\n\u001b[0;32m    206\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 207\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_assign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    209\u001b[0m train_time \u001b[38;5;241m=\u001b[39m t1\u001b[38;5;241m-\u001b[39mt0\n",
            "Cell \u001b[1;32mIn[156], line 308\u001b[0m, in \u001b[0;36mTrainMNISTCluster.train\u001b[1;34m(self, cluster_assign, lr)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m VERBOSE \u001b[38;5;129;01mand\u001b[39;00m m_i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processing \u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 308\u001b[0m     (X, y) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p_i \u001b[38;5;129;01min\u001b[39;00m cluster_assign[m_i]:\n\u001b[0;32m    312\u001b[0m         model \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[p_i])\n",
            "Cell \u001b[1;32mIn[156], line 495\u001b[0m, in \u001b[0;36mTrainMNISTCluster.load_data\u001b[1;34m(self, m_i, train)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly p=1,2,4 supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 495\u001b[0m X_batch2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrot90(X_batch, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m, dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    496\u001b[0m X_batch3 \u001b[38;5;241m=\u001b[39m X_batch2\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m28\u001b[39m)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(p_i) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "config = get_config()\n",
        "\n",
        "config['train_seed'] = config['data_seed']\n",
        "\n",
        "print(\"config:\",config)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "exp = TrainMNISTCluster(config, device)\n",
        "exp.setup()\n",
        "exp.run()\n",
        "duration = (time.time() - start_time)\n",
        "print(\"---train cluster Ended in %0.2f hour (%.3f sec) \" % (duration/float(3600), duration))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deep_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
